{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "toc-autonumbering": false,
    "colab": {
      "name": "TemsyChen_LS_DS_415_Sprint_Challenge_1_AG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlhzb8mEvlCf"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj5d2hupvlCn"
      },
      "source": [
        "# Sprint Challenge\n",
        "## *Data Science Unit 4 Sprint 1*\n",
        "\n",
        "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
        "\n",
        "## Challenge Objectives\n",
        "Successfully complete all these objectives to earn full credit. \n",
        "\n",
        "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
        "\n",
        "Each unit test that you pass is 1 point. \n",
        "\n",
        "There are 5 total possible points in this sprint challenge. \n",
        "\n",
        "\n",
        "There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernal\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "3) Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section). \n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyIzgfXcvlCs"
      },
      "source": [
        "\n",
        "\n",
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7bec125eb29f89460cf0c19ba9aa9a2f",
          "grade": false,
          "grade_id": "cell-395851cd95d17235",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "rLDtvOomvlCv"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load reviews from URL\n",
        "data_url = 'https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
        "\n",
        "# Import data into a DataFrame named df\n",
        "df = pd.read_json(data_url, lines=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "7Q8OuQ85o5RA",
        "outputId": "96501082-3529-4cc9-fc55-c365f2d16ff1"
      },
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-03-31 16:50:30</td>\n",
              "      <td>0</td>\n",
              "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
              "      <td>1</td>\n",
              "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
              "      <td>10</td>\n",
              "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-12-16 05:31:03</td>\n",
              "      <td>0</td>\n",
              "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
              "      <td>4</td>\n",
              "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
              "      <td>0</td>\n",
              "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-06-20 19:14:48</td>\n",
              "      <td>1</td>\n",
              "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
              "      <td>3</td>\n",
              "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
              "      <td>2</td>\n",
              "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
              "      <td>3</td>\n",
              "      <td>2010-07-13 00:33:45</td>\n",
              "      <td>4</td>\n",
              "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
              "      <td>1</td>\n",
              "      <td>We went here on a night where they closed off ...</td>\n",
              "      <td>5</td>\n",
              "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-06-30 02:30:01</td>\n",
              "      <td>0</td>\n",
              "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
              "      <td>5</td>\n",
              "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  cool  ... useful                 user_id\n",
              "0  nDuEqIyRc8YKS1q1fX0CZg     1  ...     10  n1LM36qNg4rqGXIcvVXv8w\n",
              "1  eMYeEapscbKNqUDCx705hg     0  ...      0  5CgjjDAic2-FAvCtiHpytA\n",
              "2  6Q7-wkCPc1KF75jZLOTcMw     1  ...      2  BdV-cf3LScmb8kZ7iiBcMA\n",
              "3  k3zrItO4l9hwfLRwHBDc9w     3  ...      5  cZZnBqh4gAEy4CdNvJailQ\n",
              "4  6hpfRwGlOzbNv7k5eP9rsQ     1  ...      5  n9QO4ClYAS7h9fpQwa5bhA\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "356579363f311da83f4ef7abaf3c9212",
          "grade": true,
          "grade_id": "cell-cb5006475e42b8f9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dOZDtoy9vlCy"
      },
      "source": [
        "# Visible Testing\n",
        "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
        "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5u2OeWOvlC0"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- accept one document at a time\n",
        "- return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHm0wi_4vlC2"
      },
      "source": [
        "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
        "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
        "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM5cLbE_vVII"
      },
      "source": [
        "#Create function to tokenize docs\n",
        "#Add some words to STOP_WORDS list\n",
        "\n",
        "STOP_WORDS = nlp.Defaults.stop_words.union([' ', '\\n', '\\n\\n', 'I'])\n",
        "\n",
        "def tokenize(doc):\n",
        "  tokens = []\n",
        "  doc = nlp(doc)\n",
        "\n",
        "  for token in doc:\n",
        "    if (token.text not in STOP_WORDS) & (token.is_punct == False):\n",
        "      tokens.append(token.text.lower())\n",
        "\n",
        "  return tokens"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2181ca9d36070260b1f75dcfd9e58965",
          "grade": true,
          "grade_id": "cell-02da164f6fbe730a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-9UnhIjQvlC5"
      },
      "source": [
        "'''Testing'''\n",
        "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZUoCeB5vlC7"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
        "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
        "    - Given the size of the dataset, use `NearestNeighbors` model for this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9f570a35b1d17ce543ee41f516a0828c",
          "grade": false,
          "grade_id": "cell-0e96491cb529202c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2Vu-UZ1evlC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "2129f3eb-1245-4c2e-ac90-919c2e0a9bd3"
      },
      "source": [
        "# Create a vector representation of the reviews \n",
        "# Name that doc-term matrix \"dtm\"\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#instantiate the vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english',\n",
        "                        ngram_range=(1,2),\n",
        "                        min_df=3,\n",
        "                        max_df=0.25)\n",
        "\n",
        "#build the vocabulary, transform text\n",
        "dtm = tfidf.fit_transform(df['text'])\n",
        "\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "print(dtm.shape)\n",
        "dtm.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 31690)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>00 extra</th>\n",
              "      <th>00 pm</th>\n",
              "      <th>000</th>\n",
              "      <th>00am</th>\n",
              "      <th>00pm</th>\n",
              "      <th>01</th>\n",
              "      <th>04</th>\n",
              "      <th>05</th>\n",
              "      <th>06</th>\n",
              "      <th>07</th>\n",
              "      <th>08</th>\n",
              "      <th>10</th>\n",
              "      <th>10 00</th>\n",
              "      <th>10 10</th>\n",
              "      <th>10 12</th>\n",
              "      <th>10 15</th>\n",
              "      <th>10 20</th>\n",
              "      <th>10 30</th>\n",
              "      <th>10 30am</th>\n",
              "      <th>10 50</th>\n",
              "      <th>10 55</th>\n",
              "      <th>10 95</th>\n",
              "      <th>10 came</th>\n",
              "      <th>10 coupon</th>\n",
              "      <th>10 days</th>\n",
              "      <th>10 different</th>\n",
              "      <th>10 dinner</th>\n",
              "      <th>10 dollars</th>\n",
              "      <th>10 drinks</th>\n",
              "      <th>10 food</th>\n",
              "      <th>10 hours</th>\n",
              "      <th>10 lunch</th>\n",
              "      <th>10 min</th>\n",
              "      <th>10 mins</th>\n",
              "      <th>10 minute</th>\n",
              "      <th>10 minutes</th>\n",
              "      <th>10 months</th>\n",
              "      <th>10 oz</th>\n",
              "      <th>10 people</th>\n",
              "      <th>...</th>\n",
              "      <th>yummmm</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yummy breakfast</th>\n",
              "      <th>yummy came</th>\n",
              "      <th>yummy dessert</th>\n",
              "      <th>yummy food</th>\n",
              "      <th>yummy good</th>\n",
              "      <th>yummy looking</th>\n",
              "      <th>yummy place</th>\n",
              "      <th>yummy service</th>\n",
              "      <th>yummy tummy</th>\n",
              "      <th>yummy want</th>\n",
              "      <th>yummy yummy</th>\n",
              "      <th>yup</th>\n",
              "      <th>yuppie</th>\n",
              "      <th>yuzu</th>\n",
              "      <th>zach</th>\n",
              "      <th>zack</th>\n",
              "      <th>zen</th>\n",
              "      <th>zero</th>\n",
              "      <th>zero customer</th>\n",
              "      <th>zero star</th>\n",
              "      <th>zero stars</th>\n",
              "      <th>zest</th>\n",
              "      <th>zing</th>\n",
              "      <th>zip</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombies</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>zucchini</th>\n",
              "      <th>zucchini fries</th>\n",
              "      <th>zumba</th>\n",
              "      <th>ça</th>\n",
              "      <th>équipe</th>\n",
              "      <th>érable</th>\n",
              "      <th>était</th>\n",
              "      <th>était très</th>\n",
              "      <th>été</th>\n",
              "      <th>être</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31690 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  00 extra  00 pm  000  00am  ...  érable  était  était très  été  être\n",
              "0  0.0       0.0    0.0  0.0   0.0  ...     0.0    0.0         0.0  0.0   0.0\n",
              "1  0.0       0.0    0.0  0.0   0.0  ...     0.0    0.0         0.0  0.0   0.0\n",
              "2  0.0       0.0    0.0  0.0   0.0  ...     0.0    0.0         0.0  0.0   0.0\n",
              "3  0.0       0.0    0.0  0.0   0.0  ...     0.0    0.0         0.0  0.0   0.0\n",
              "4  0.0       0.0    0.0  0.0   0.0  ...     0.0    0.0         0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 31690 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "32b220e23c9aa1f602f08d1c2e879d0a",
          "grade": false,
          "grade_id": "cell-3d5bc610a8ec6b24",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Y2i0VqYUvlC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdd2271-16fc-4756-aae4-288088ce6b0f"
      },
      "source": [
        "# Create and fit a NearestNeighbors model named \"nn\"\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "#fit on dtm\n",
        "nn = NearestNeighbors(n_neighbors=10)\n",
        "nn.fit(dtm)\n",
        "\n",
        "#sample a doc from dtm to use as query point\n",
        "doc = dtm.iloc[0].values\n",
        "\n",
        "#query using kneighbors\n",
        "nn.kneighbors([doc])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 1.        , 1.        , 1.29367092, 1.29654258,\n",
              "         1.31654242, 1.3287342 , 1.33418235, 1.33872057, 1.34074972]]),\n",
              " array([[   0, 6311, 6204, 3276, 2131, 2943, 6019,   14, 4386, 8470]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okDqK0AT7rNU",
        "outputId": "25ee144d-5fdf-4833-93ef-9dbc71380525"
      },
      "source": [
        "print(df['text'][0])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEWARE!!! FAKE, FAKE, FAKE....We also own a small business in Los Alamitos, CA and received what looked like a legitimate bill for $70 with an account number and all.  I called the phone number listed (866) 273-7934.  The wait time on hold said 20 minutes and to leave a message.  I could not get a live person on the phone no matter what number I selected.  I left a very FIRM message that I would be contacting the BBB and my attorney regarding their company trying to scam businesses. This has to be illegal!!!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KHchd4l70h6",
        "outputId": "b28ec3fe-3126-4634-f50c-65af05b8afcd"
      },
      "source": [
        "print(df['text'][2131])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Haven't even gotten the chance to hear a quote or anything from them because they never pick up the phone. I've called several times over the past three days (always during normal business hours!!!) because I'm shopping for car insurance. The phone rings several times, and eventually goes to a message stating their business hours (and confirming that I was indeed calling when they were supposedly open). Then it tells me to leave a message and lists extensions of people there to leave messages with.\n",
            "\n",
            "If they can't be bothered to pick up the phone to get new customers, I can only imagine how unavailable they must be to any customer who gets into an accident.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
          "grade": true,
          "grade_id": "cell-c43704dcff67e99b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4EunRNKkvlDA"
      },
      "source": [
        "'''Testing.'''\n",
        "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
        "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
          "grade": false,
          "grade_id": "cell-496203e8746296ca",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "dDxVIIuYvlDC"
      },
      "source": [
        "# Create a fake review and find the 10 most similar reviews\n",
        "\n",
        "fake_review = [\"This place has the best gelato. I eat gelato three or four times a week, and this gelateria never disappoints. The flavors are always changing, and tastes so authentic and good!\"]\n",
        "\n",
        "doc = tfidf.transform(fake_review)\n",
        "\n",
        "k = nn.kneighbors(doc.todense())"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCneaEVe9_Tl",
        "outputId": "44886fd7-f44c-4c15-ddde-eb7f2698c81a"
      },
      "source": [
        "\n",
        "for doc in k[1][0]:\n",
        "  print(\"Review:\", df['text'][doc])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: 天氣很熱吃不下東西，今天我點了一個韓國冷面湯、餐後點了甜點，冰沙系列不會太甜膩，覺得店家很用心製作，包含擺盤精緻、佐料衛生，夏日想開胃，這是一個不錯的選擇，服務人員也很敬業，以後會常常來\n",
            "Review: 旅行でラスベガスに来ましたがネイルがはげてるのが気になり、探したお店でした。\n",
            "質問にも丁寧に答えてくれましたし、日本人の方も日本語が話せる方も居て、とても綺麗で居心地のいいお店でした。 \n",
            "ネイルはちはるさんと言う綺麗な方が丁寧にしてくれとても気に入りました。\n",
            "予定になかったまつ毛エクステもお願いし、日本ではまだあまりないブラウンカラーのエクステをしてもらい、とても気に入りました。\n",
            "また是非マッサージなどで伺いたいと思います。\n",
            "Review: I stopped in because I was craving Gelato, and was pleasantly surprised with the variety of flavors they sell! They also had sugar-free and vegan gelatos, which caters to everyone's tastes. I ordered the bubblegum gelato and it was amazing, with loads of actual bubblegum pieces!!\n",
            "Review: I've eaten here several times but never disappoints. Although you can never take from dining in Italia, this gets close. Love when. they offer the guanciale. Have an order of prosciutto and buratta and you are transported. Finish with an amaro and homemade gelato and enjoy.\n",
            "Review: Great little pizza and gelato shop. It reminded me of being back in Italy. If I ever return to Pittsburg it will be to eat here.\n",
            "Review: They always have such a wide variety of tasty, creative gelato flavors. They have multiple large cases of ice cream. Sometimes there are empty slots, but they usually have more gelato than not. They have regular flavors as well as seasonal flavors which are easily distinguishable by signs. Service is always great. They're always kind and helpful. More importantly, they're always patient when I ask to try a bunch of their new flavors and knowledgeable about the ice cream, particularly when I ask them for distinguishing features between coffee flavors. Price and size portion is pretty average. There is indoor seating, but it is limited. They do have an outdoor patio but no seats. The place is usually clean and kept.\n",
            "Review: Real Ecuadorian helado de paila or Gelato!! Beautifully fresh and flavorful Gelato!. Also wonderful service to boot!! My favorite is key lime and twighlight flavored! The owners are amazingly sweet people come support this business!! You wont be disappointed!\n",
            "Review: The gelato here is amazing! It's gotten to the point where my husband and I refuse to eat frozen dessert anywhere else. We come about once a week and leave with a pint to go (each). Mint chocolate and dolce latte are definitely the best. I don't know what I'll do if I ever leave the area, definitely a hard place to beat and it's ruined me for store-bought ice cream and gelato.\n",
            "Review: We're from the DC area but stopped in based on Yelp reviews. My kids LOVED the cannoli gelato and the coffee and chocolate gelato. They had much sexier names but I can't remember them! I highly recommend. Very clean, excellent customer service, great location to just hang out, too!\n",
            "Review: Great causal dinning! Casey is the best server! Clean and very good service. Would eat here several times a week!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxBl99epvlDD"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset. \n",
        "\n",
        "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
        "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels). \n",
        "    - Use that Pipeline to predict a star rating for your fake review from Part 2. \n",
        "\n",
        "\n",
        "\n",
        "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`. \n",
        "    - Include 2 possible values for each parameter\n",
        "    - **Use `n_jobs` = 1** \n",
        "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
        "    \n",
        "    \n",
        "3. Train the entire pipeline with a GridSearch\n",
        "    - Name your GridSearch object as `gs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e1d18da8521d51d8bfc4b5b9d005fa34",
          "grade": false,
          "grade_id": "cell-e2beb0252d274bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "nkEpE7tLvlDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77564d9-f532-4829-e5e9-1e1ce20d27f3"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Name the gridsearch instance \"gs\"\n",
        "\n",
        "#word embedding\n",
        "svd = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=10)\n",
        "\n",
        "#vectorizer\n",
        "vect = TfidfVectorizer(stop_words='english',\n",
        "                       ngram_range=(1,2),\n",
        "                       min_df=2,\n",
        "                       max_df=0.3)\n",
        "\n",
        "#classifier\n",
        "kn = KNeighborsClassifier()\n",
        "\n",
        "pipe = Pipeline([\n",
        "                 ('vect', vect),\n",
        "                 ('svd', svd),\n",
        "                 ('clf', kn)\n",
        "])\n",
        "\n",
        "pipe"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=0.3, max_features=None,\n",
              "                                 min_df=2, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('svd',\n",
              "                 TruncatedSVD(algorithm='randomized', n_components=2, n_iter=10,\n",
              "                              random_state=None, tol=0.0)),\n",
              "                ('clf',\n",
              "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                      metric='minkowski', metric_params=None,\n",
              "                                      n_jobs=None, n_neighbors=5, p=2,\n",
              "                                      weights='uniform'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khzUyoIBCKYQ",
        "outputId": "99e6d84c-36d4-4214-faee-bff4a8686150"
      },
      "source": [
        "#Tune hyperparameters for the pipeline\n",
        "\n",
        "parameters = {\n",
        "    'vect__max_features': (10000, 20000),\n",
        "    'clf__algorithm': ('kd_tree', 'brute')\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(pipe, parameters, cv=5, n_jobs=1, verbose=1)\n",
        "gs.fit(df['text'], df['stars'])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=0.3,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=2,\n",
              "                                                        ngram_range=(1, 2),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words='english',\n",
              "                                                        strip...\n",
              "                                       ('clf',\n",
              "                                        KNeighborsClassifier(algorithm='auto',\n",
              "                                                             leaf_size=30,\n",
              "                                                             metric='minkowski',\n",
              "                                                             metric_params=None,\n",
              "                                                             n_jobs=None,\n",
              "                                                             n_neighbors=5, p=2,\n",
              "                                                             weights='uniform'))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=1,\n",
              "             param_grid={'clf__algorithm': ('kd_tree', 'brute'),\n",
              "                         'vect__max_features': (10000, 20000)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZODLwG2YIIpL",
        "outputId": "1b9e4d39-4bbd-40e2-ba5d-b810f3abb692"
      },
      "source": [
        "gs.best_score_"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36970000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Iu58KlZIN0s",
        "outputId": "40c2ac5d-5dd7-4fee-c7a6-41da276b430f"
      },
      "source": [
        "gs.best_params_"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__algorithm': 'kd_tree', 'vect__max_features': 20000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD6ANf7xIUXP",
        "outputId": "028f01a1-632f-4c30-fbb0-f48f521cda08"
      },
      "source": [
        "#Prediction\n",
        "\n",
        "fake_review = [\"This place has the best gelato. I eat gelato three or four times a week, and this gelateria never disappoints. The flavors are always changing, and tastes so authentic and good!\"]\n",
        "\n",
        "pred = gs.predict(fake_review)\n",
        "pred"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJYyjj9HJGQs",
        "outputId": "e92379e1-1ee8-46bf-b74d-e49c165d911e"
      },
      "source": [
        "fake_review = [\"I dread coming to this store. The customer service is middling at best. It just feels cold and unwelcoming. And there's too much junk food.\"]\n",
        "\n",
        "pred = gs.predict(fake_review)\n",
        "pred"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b9e2378efb868f104a4eb39e4f25563c",
          "grade": true,
          "grade_id": "cell-d07134c6fe5d056e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AzFefoyxvlDJ"
      },
      "source": [
        "# Visible Testing\n",
        "prediction = gs.predict([\"I wish dogs knew how to speak English.\"])[0]\n",
        "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrg3DOeNvlDK"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Set num_topics to `5`\n",
        "    - Name your LDA model `lda`\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "When you instantiate your LDA model, it should look like this: \n",
        "\n",
        "```python\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )\n",
        "\n",
        "```\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NppSus8zvlDN"
      },
      "source": [
        "## Note about  pyLDAvis\n",
        "\n",
        "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
        "\n",
        "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.** \n",
        "\n",
        "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp-C6cxyvlDO"
      },
      "source": [
        "from gensim import corpora\n",
        "# Due to limited computationalresources on CodeGrader, use the non-multicore version of LDA \n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import gensim\n",
        "import re"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNDURUy3vlDP"
      },
      "source": [
        "### 1. Estimate a LDA topic model of the review tex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9514841e71735eaa255bccc53b257896",
          "grade": false,
          "grade_id": "cell-66331a185ff52f15",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "j1AF0LBFvlDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ba57b652-08f7-4475-f30b-daf1b4864499"
      },
      "source": [
        "# Remember to read the LDA docs for more information on the various class attirbutes and methods available to you\n",
        "# in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html\n",
        "\n",
        "# use tokenize function you created earlier to create tokens \n",
        "df['tokens'] = df['text'].apply(tokenize)\n",
        "df.head()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-03-31 16:50:30</td>\n",
              "      <td>0</td>\n",
              "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
              "      <td>1</td>\n",
              "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
              "      <td>10</td>\n",
              "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
              "      <td>[beware, fake, fake, fake, we, small, business...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-12-16 05:31:03</td>\n",
              "      <td>0</td>\n",
              "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
              "      <td>4</td>\n",
              "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
              "      <td>0</td>\n",
              "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
              "      <td>[came, lunch, togo, service, quick, staff, fri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-06-20 19:14:48</td>\n",
              "      <td>1</td>\n",
              "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
              "      <td>3</td>\n",
              "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
              "      <td>2</td>\n",
              "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
              "      <td>[vegas, dozens, times, stepped, foot, circus, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
              "      <td>3</td>\n",
              "      <td>2010-07-13 00:33:45</td>\n",
              "      <td>4</td>\n",
              "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
              "      <td>1</td>\n",
              "      <td>We went here on a night where they closed off ...</td>\n",
              "      <td>5</td>\n",
              "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
              "      <td>[we, went, night, closed, street, party, and, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-06-30 02:30:01</td>\n",
              "      <td>0</td>\n",
              "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
              "      <td>5</td>\n",
              "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
              "      <td>[3.5, 4, stars, not, bad, price, $, 12.99, lun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  ...                                             tokens\n",
              "0  nDuEqIyRc8YKS1q1fX0CZg  ...  [beware, fake, fake, fake, we, small, business...\n",
              "1  eMYeEapscbKNqUDCx705hg  ...  [came, lunch, togo, service, quick, staff, fri...\n",
              "2  6Q7-wkCPc1KF75jZLOTcMw  ...  [vegas, dozens, times, stepped, foot, circus, ...\n",
              "3  k3zrItO4l9hwfLRwHBDc9w  ...  [we, went, night, closed, street, party, and, ...\n",
              "4  6hpfRwGlOzbNv7k5eP9rsQ  ...  [3.5, 4, stars, not, bad, price, $, 12.99, lun...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du0p0PCSLQn9"
      },
      "source": [
        "# create a id2word object (hint: use corpora.Dictionary)\n",
        "id2word = corpora.Dictionary(df['tokens'])\n",
        "\n",
        "# create a corpus object (hint: id2word.doc2bow)\n",
        "corpus = [id2word.doc2bow(text) for text in df['tokens']]\n",
        "\n",
        "# don't change this value \n",
        "num_topics = 5\n",
        "\n",
        "# instantiate an lda model\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1MAkYTTvlDS"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6479db0fa59c99d3ae3201c1f10ebca1",
          "grade": true,
          "grade_id": "cell-5a3c181311134fa9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tqEnU9qmvlDV"
      },
      "source": [
        "# Visible Testing\n",
        "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjtrtlecvlDX"
      },
      "source": [
        "#### 2. Create 1-2 visualizations of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "189591ed7b9e6e6146d59761fb418268",
          "grade": false,
          "grade_id": "cell-9b043e992fbd218c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "WcHdJLHpvlDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db56980-1747-4351-ce8f-429bfe482c57"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# !pip install pyLDAvis\n",
        "\n",
        "# Use pyLDAvis (or a ploting tool of your choice) to visualize your results "
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/38/6d81eff34c84c9158d3b7c846bff978ac88b0c2665548941946d3d591158/pyLDAvis-3.2.2.tar.gz (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis) (1.15.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135593 sha256=e048b9fbc597ad23576490f00441852923bccea179ca32a3ef54afc5f1cc4293\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/df/b6/97234c8446a43be05c9a8687ee0db1f1b5ade5f27729187eae\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.15 pyLDAvis-3.2.2\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyLDAvis.gensim (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pyLDAvis.gensim\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "BfVZnggiOELo",
        "outputId": "c9a64a0a-5596-446b-f13e-38e33e8b08d6"
      },
      "source": [
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim\n",
        "\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis = pyLDAvis.gensim.prepare(lda, corpus, id2word)\n",
        "# vis"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el591396856369193762067976602\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el591396856369193762067976602_data = {\"mdsDat\": {\"x\": [-0.10767636402519679, 0.07968174305913202, 0.08077145247457573, -0.06961329433449401, 0.016836462825983143], \"y\": [0.051738577980254156, 0.03332637792584295, -0.01810784134736599, -0.06368364552555843, -0.0032734690331726345], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [28.200425702869953, 23.890856377526976, 22.39358821528168, 13.520077248809221, 11.995052455512173]}, \"tinfo\": {\"Term\": [\"food\", \"the\", \"room\", \"good\", \"cheese\", \"it\", \"restaurant\", \"delicious\", \"chicken\", \"menu\", \"pizza\", \"ordered\", \"meat\", \"service\", \"hotel\", \"sushi\", \"we\", \"car\", \"sauce\", \"hair\", \"like\", \"customer\", \"fries\", \"salad\", \"fresh\", \"told\", \"lunch\", \"called\", \"burger\", \"eat\", \"yuk\", \"ikea\", \"acrylic\", \"dunkin\", \"promotion\", \"warranty\", \"jessica\", \"emailed\", \"heartbeat\", \"dissatisfied\", \"repair\", \"250\", \"procedure\", \"arrogant\", \"victor\", \"nails\", \"billing\", \"unorganized\", \"designs\", \"pt\", \"nancy\", \"values\", \"manicures\", \"acura\", \"doctor\", \"bouncers\", \"biryani\", \"coney\", \"interactive\", \"victoria\", \"gel\", \"contacted\", \"paperwork\", \"nail\", \"phone\", \"tech\", \"repaired\", \"car\", \"situation\", \"insurance\", \"manicure\", \"dealership\", \"sessions\", \"patients\", \"salon\", \"quote\", \"rude\", \"polish\", \"company\", \"customer\", \"pedicure\", \"office\", \"called\", \"tire\", \"appointment\", \"sales\", \"told\", \"help\", \"fixed\", \"manager\", \"store\", \"he\", \"care\", \"work\", \"needed\", \"services\", \"fix\", \"said\", \"job\", \"she\", \"business\", \"minutes\", \"time\", \"asked\", \"know\", \"going\", \"service\", \"they\", \"left\", \"people\", \"day\", \"got\", \"$\", \"great\", \"place\", \"the\", \"went\", \"we\", \"experience\", \"this\", \"staff\", \"like\", \"recommend\", \"good\", \"my\", \"tamale\", \"margarita\", \"tile\", \"ami\", \"persian\", \"ethiopian\", \"pakora\", \"yellowtail\", \"baba\", \"relleno\", \"chunky\", \"gabi\", \"pico\", \"tilapia\", \"humor\", \"dans\", \"arepa\", \"ranchero\", \"4.50\", \"avec\", \"cuban\", \"pinch\", \"frittata\", \"rewards\", \"froyo\", \"pee\", \"knife\", \"volcano\", \"tr\\u00e8s\", \"ganoush\", \"byob\", \"est\", \"thai\", \"smokey\", \"salsa\", \"burrito\", \"de\", \"tortilla\", \"un\", \"et\", \"mon\", \"taco\", \"\\u00e0\", \"burritos\", \"sushi\", \"les\", \"guacamole\", \"curry\", \"le\", \"basil\", \"food\", \"tacos\", \"brunch\", \"sashimi\", \"chorizo\", \"rolls\", \"chicken\", \"delicious\", \"good\", \"asada\", \"lunch\", \"wine\", \"breakfast\", \"friendly\", \"server\", \"service\", \"great\", \"tasty\", \"the\", \"fresh\", \"fried\", \"ordered\", \"bar\", \"restaurant\", \"place\", \"we\", \"order\", \"atmosphere\", \"menu\", \"nice\", \"my\", \"amazing\", \"try\", \"like\", \"time\", \"it\", \"this\", \"definitely\", \"love\", \"best\", \"got\", \"went\", \"staff\", \"they\", \"introduced\", \"nyc\", \"flies\", \"earl\", \"pearls\", \"doughnuts\", \"slider\", \"specially\", \"macaroni\", \"alfredo\", \"philly\", \"ragu\", \"momofuku\", \"breasts\", \"done\", \"grub\", \"calzone\", \"cajun\", \"marshmallows\", \"boba\", \"gumbo\", \"und\", \"rick\", \"lox\", \"sourced\", \"albeit\", \"bleu\", \"hesitation\", \"hotpot\", \"samosa\", \"poutine\", \"ale\", \"gelato\", \"brulee\", \"chocolate\", \"frosting\", \"cookies\", \"shakes\", \"protein\", \"moist\", \"enchiladas\", \"meat\", \"cheese\", \"broth\", \"milk\", \"chewy\", \"tea\", \"ramen\", \"vegan\", \"pork\", \"fries\", \"donuts\", \"cream\", \"salad\", \"sweet\", \"cake\", \"creamy\", \"burger\", \"ice\", \"sauce\", \"menu\", \"flavor\", \"dishes\", \"taste\", \"dessert\", \"the\", \"perfect\", \"green\", \"try\", \"it\", \"place\", \"best\", \"steak\", \"like\", \"little\", \"delicious\", \"ordered\", \"good\", \"food\", \"great\", \"we\", \"they\", \"$\", \"chicken\", \"definitely\", \"love\", \"got\", \"this\", \"time\", \"came\", \"my\", \"greatest\", \"surgery\", \"iphone\", \"stunning\", \"accessories\", \"facials\", \"ihop\", \"rain\", \"photography\", \"cox\", \"harness\", \"frustration\", \"appreciates\", \"blind\", \"therapist\", \"technique\", \"scorpions\", \"reach\", \"rita\", \"coca\", \"boots\", \"acts\", \"talent\", \"channels\", \"crackers\", \"gyms\", \"towed\", \"ipad\", \"terrified\", \"massages\", \"jewelry\", \"cats\", \"shower\", \"massage\", \"motel\", \"dentist\", \"gym\", \"room\", \"spa\", \"artist\", \"rooms\", \"pool\", \"desk\", \"hotel\", \"bathroom\", \"skin\", \"lobby\", \"tour\", \"pet\", \"stay\", \"relaxing\", \"hotels\", \"park\", \"hair\", \"bed\", \"kids\", \"clean\", \"like\", \"there\", \"the\", \"stayed\", \"water\", \"it\", \"coffee\", \"vegas\", \"time\", \"nice\", \"years\", \"people\", \"experience\", \"2\", \"you\", \"day\", \"place\", \"this\", \"little\", \"great\", \"definitely\", \"$\", \"love\", \"they\", \"staff\", \"we\", \"good\", \"best\", \"recommend\", \"come\", \"amazing\", \"got\", \"cirque\", \"painting\", \"urban\", \"skinny\", \"sampling\", \"concoction\", \"anything\", \"married\", \"pa\", \"chilli\", \"mule\", \"tai\", \"cesar\", \"char\", \"ears\", \"church\", \"luxurious\", \"computers\", \"india\", \"accent\", \"2012\", \"floral\", \"spell\", \"chains\", \"homes\", \"ramsay\", \"overlooked\", \"fishy\", \"bobbie\", \"minced\", \"angeles\", \"upgraded\", \"clam\", \"fe\", \"pig\", \"theater\", \"bagel\", \"fi\", \"theaters\", \"bay\", \"movie\", \"pho\", \"roll\", \"nacho\", \"pizza\", \"theatre\", \"library\", \"restaurant\", \"seats\", \"the\", \"it\", \"good\", \"we\", \"fish\", \"food\", \"roof\", \"area\", \" \\n\\n\", \"like\", \"hotel\", \"$\", \"pretty\", \"come\", \"place\", \"night\", \"time\", \"ok\", \"this\", \"great\", \"vegas\", \"ordered\", \"got\", \"my\", \"they\", \"service\", \"nice\", \"came\", \"order\", \"if\", \"want\", \"people\", \"love\", \"chicken\"], \"Freq\": [4777.0, 9198.0, 875.0, 4524.0, 833.0, 3019.0, 1278.0, 1248.0, 1391.0, 1233.0, 751.0, 1529.0, 586.0, 3546.0, 391.0, 539.0, 3499.0, 609.0, 787.0, 384.0, 3321.0, 810.0, 601.0, 657.0, 913.0, 954.0, 743.0, 633.0, 549.0, 824.0, 57.20536140834523, 20.080700568880086, 21.242486744606364, 21.34944997556663, 16.61347703005764, 67.57933041928588, 20.684577907226828, 23.035213568061607, 17.07265229709946, 14.396183781298449, 117.28165591021768, 13.2402887100928, 44.73469128782491, 12.205809638414246, 12.243899485745517, 183.50332260525144, 17.560628022750272, 17.52186746143183, 14.799015719848217, 14.794834935994869, 12.449768436966876, 13.923095670449475, 14.131448499136644, 11.458619724572666, 103.32687906458433, 17.86923694252603, 12.858719522792905, 13.318387764615292, 17.063850293874523, 13.864784914261731, 98.52485308776238, 39.03520528190633, 26.920550145774797, 173.849906102152, 310.7696919568169, 68.13397958668779, 30.237803154923117, 520.8521221026823, 98.15972533600127, 90.04427389118445, 48.917733211595795, 63.21033080685937, 26.096294076950965, 37.056889662488395, 185.10554206350477, 55.55258800116576, 278.3654602662082, 73.40013069977684, 299.23305366340026, 641.9346694639154, 102.78295684955053, 265.04009036898645, 502.30056670315355, 74.44081499369335, 258.6439829302888, 82.95530101803591, 702.7837024932574, 268.01872224314656, 97.42287894969847, 331.919503914103, 484.7747923327465, 589.0438814636512, 368.4375017164614, 585.8724953324323, 315.955366334299, 122.66143491558617, 172.19308158249004, 654.0674025777143, 321.9305515603563, 447.67572370331834, 302.8341975461839, 507.8881686731593, 1372.0219758038722, 458.40843526886226, 606.4605887968917, 584.6667483262737, 1304.6193338059395, 957.914932701418, 351.12131205276455, 589.0805113902038, 519.8052359400978, 713.3917149143069, 706.6501629436583, 1024.2832085311936, 1035.311391965218, 1437.7838546464227, 555.0421521412588, 831.8727862906443, 500.97702443514197, 624.9115549840516, 543.6259919656438, 704.3818976675876, 464.6536588890066, 577.2476858000538, 499.8504753365882, 26.679358029316305, 63.253537608873536, 14.732817610034656, 19.17795484767193, 13.753552356510811, 15.509849126602942, 12.804203672486866, 30.348608705514305, 11.528039905584214, 15.7688836234656, 13.691020191772648, 13.360928396944916, 19.238291804809563, 10.988397646483532, 13.724243778071969, 16.98902792738542, 10.842810304103363, 10.576327443229413, 10.53974570069563, 16.055850669153823, 13.001113226038552, 10.921385099019695, 10.023523408791295, 10.004925700914146, 13.379152029324992, 10.159912282049826, 15.23146024762982, 10.23835922837855, 22.99448141463308, 8.850535346140173, 22.003516594803383, 28.930603086335065, 201.3574115966727, 22.05969231717107, 186.93407564211705, 120.28530760242879, 127.76741606463692, 54.228976659336645, 52.01190789735153, 59.319820291379465, 35.10601753892013, 185.0770853244261, 47.091726030311506, 30.001360577256364, 413.6031741113807, 39.95253967896735, 83.99138538527689, 115.51476351042963, 63.856070008757676, 38.429584574761854, 2792.294733981511, 238.5244923158477, 143.3701864917388, 77.33918282736477, 34.26412227818636, 178.72750700256438, 768.0767969345908, 687.4500757503984, 2050.298412516772, 44.60880796823101, 424.75011631784173, 232.19749110753074, 285.8524105620362, 691.2599409324318, 362.6871161210781, 1478.7408123559214, 1682.4296518556532, 292.2145502443869, 3132.683904839714, 465.7394569028621, 283.57309184923224, 681.6252410655616, 483.4423383099536, 585.0090141059438, 1533.3935493145523, 1162.7847453000652, 596.7086258690694, 252.00105928676936, 483.6823224202363, 582.1882386311217, 627.5464173637225, 512.1231214679993, 494.92369454052994, 772.3425682859756, 764.3814234773517, 712.1252546977055, 573.0484169712115, 452.1306395648141, 475.49643684107866, 490.10734466715786, 503.708585792607, 451.94435564943234, 446.13146107565143, 447.4550557215295, 30.24315434527812, 44.24595882798247, 19.564209197290435, 21.53000343560184, 16.037152109227094, 13.62583363691674, 17.230061665021786, 11.869702978850695, 24.02015457611897, 19.56959738637267, 28.17772565573637, 13.24169658841729, 17.854395661124364, 14.665332484019663, 13.23356281962643, 23.346790722393962, 9.733112911060767, 31.860488093146767, 10.459834039504727, 61.7531065631264, 10.597059764417851, 9.00938147303344, 9.339935777287268, 9.199238354268603, 12.274003571831686, 9.617218023651118, 14.70234321805503, 9.391588715426666, 9.040439456494598, 9.754987005848976, 55.91919085692391, 26.73402297226036, 47.67486743327077, 26.015382352089148, 250.8237205229228, 25.055700605102746, 67.84768634636679, 30.86225460780099, 36.99360900344646, 47.40384951151208, 42.92806636503778, 444.875279440672, 615.595862459205, 113.78127570472208, 103.63673061730525, 47.43134614166221, 238.25513302541887, 148.4782095010922, 85.31359978838914, 258.03127470102623, 383.816626121092, 90.44630171594636, 350.06434217814666, 404.27181809840795, 368.81536800956695, 134.39851458374156, 86.60077158448738, 316.6158846361165, 262.6228710687824, 399.3958247667436, 573.197479048184, 261.457332093245, 244.5108294266464, 318.3230333710264, 206.5617870902082, 2408.5082343327426, 276.9500640630939, 172.8310630049943, 539.4008823541703, 905.1271971245156, 1206.1632013803487, 605.2017953951391, 219.08276678592327, 877.2260142816167, 484.34535695753283, 443.67590938403043, 500.6195556547168, 933.0339474669079, 821.7660498146511, 724.7949795599802, 645.9927053555443, 532.4460528852051, 488.73640972109484, 398.34226070448284, 394.89032580186455, 402.9079511562298, 426.44043645036857, 422.0491280363196, 428.30645776010255, 360.8126556002728, 359.11709635410386, 29.686291421332815, 27.89309538413738, 21.671363152276466, 16.21839202707095, 18.043292724591563, 24.42765885587904, 14.713853207638463, 16.007215558361906, 22.845017606369332, 23.757881158637375, 25.14666940271183, 15.042497377566491, 11.408740712245931, 14.105192114307714, 26.542887806878714, 19.713067928837873, 13.491347487479128, 24.16492573678828, 10.118086961429235, 9.950014424912505, 8.718023781692303, 13.443988255868614, 12.605965452033058, 10.825117286197232, 12.7385700143059, 13.435957852029532, 9.938462948381034, 16.09333660177604, 7.887540468060177, 24.893218624417443, 30.225983436309892, 31.86729851205443, 62.25667687111253, 112.75982659072162, 20.287409014090198, 42.67812785335377, 83.95099077178762, 581.934665992238, 74.83446302296814, 21.672932360928417, 125.43145227745494, 143.38965616350384, 97.41444943418811, 213.92697420422004, 72.76957308503556, 75.16304502479383, 55.70771318585588, 53.63552171149086, 38.61927535106571, 158.49871735698207, 51.80284464185966, 43.19587667193554, 87.85013127545868, 149.5837428833763, 62.79185419562375, 138.8762176346027, 208.4772240298336, 559.5622438686089, 239.13530793326163, 1041.2149760001728, 70.501492063952, 140.01211890075908, 434.2172181157606, 165.6646673019627, 203.9285597679149, 436.5872548246676, 283.5885537683984, 157.37211129398807, 243.40676248315702, 226.0767822772604, 204.39256533389502, 175.17983407275236, 216.8280551306971, 405.4824180755203, 285.1963152187053, 232.83598990969114, 381.2746220728553, 228.47338405941193, 271.51461650493434, 236.7016282373886, 272.8713217207505, 228.088644967632, 301.800257738478, 281.4916794136802, 210.9377260462711, 189.18286898883593, 189.1205122384699, 182.79349725344696, 185.1126675922809, 24.570549380646234, 27.448017793378664, 17.798405969106764, 14.527184646934828, 14.650417749612343, 12.895659313264227, 13.572643521914795, 11.372255364869465, 12.810228802629467, 12.457990085070282, 10.161523509785477, 9.913328457772826, 11.081918486876368, 9.666768107302776, 13.002512116889205, 31.076045297629342, 9.313313110934406, 9.6183356759097, 11.28585202137951, 8.521817060715806, 10.15681149923074, 10.910890096513482, 10.881913371263563, 21.550136350649293, 8.20464882494231, 8.626128897196029, 10.01271621944933, 16.367725449398076, 7.428741398945406, 9.253856191476538, 12.334289109699945, 22.871429756313553, 30.327629671659103, 12.644666534702226, 27.27201968209569, 39.413215258970276, 32.32699423412006, 17.433503307136395, 12.502107056544611, 26.88829750672911, 52.27861119707933, 60.11714108124208, 118.60634385279187, 14.688195616675397, 253.4667067771756, 18.79535518911942, 22.73056393926552, 300.1534937418053, 57.71514734162863, 1178.4742695736575, 535.1062574411429, 682.8731434544876, 557.0219925570373, 117.8251866479317, 613.6178210483438, 26.35757962126993, 168.28740193618748, 140.70479276484053, 408.18373133093405, 107.37606788001777, 299.8413351673037, 193.78503344997324, 229.81539980918186, 453.58548882743617, 167.78864203795382, 332.5474470248013, 111.08572014995063, 252.68550392619906, 357.68768466276, 153.50230532021715, 201.11125034318263, 227.66073574729148, 217.1315765143178, 232.77428758007278, 276.17120678399226, 193.8172900388767, 181.05227751835753, 175.25194943400294, 151.11006843797838, 144.16922648993256, 152.8207631566546, 155.39984480857945, 148.70562882729595], \"Total\": [4777.0, 9198.0, 875.0, 4524.0, 833.0, 3019.0, 1278.0, 1248.0, 1391.0, 1233.0, 751.0, 1529.0, 586.0, 3546.0, 391.0, 539.0, 3499.0, 609.0, 787.0, 384.0, 3321.0, 810.0, 601.0, 657.0, 913.0, 954.0, 743.0, 633.0, 549.0, 824.0, 58.47195295406957, 20.857203490204203, 22.18687136326154, 22.33498573395806, 17.39291895796432, 70.93585504718568, 21.746430482691835, 24.29200722913178, 18.012148333836432, 15.200109658140317, 124.02881609608761, 14.023264339620143, 47.469633483323626, 12.96406020594064, 13.006235308649723, 194.99544696338813, 18.665761432562228, 18.625996997002904, 15.743157417753464, 15.740741397894011, 13.246191141207316, 14.813900241744694, 15.04583718545677, 12.213405734181821, 110.19493600951954, 19.088590799164795, 13.751282396838304, 14.24905384992963, 18.270549405188365, 14.853738809719662, 105.64646515585515, 42.078789043197595, 28.93964149617105, 193.52540685919163, 350.35783382336615, 74.69717845714263, 32.669802468099626, 609.302524934787, 109.42388963820176, 100.69257281336564, 53.751692452425786, 70.03315591573916, 28.15629367271339, 40.42238053444048, 213.60722895767228, 61.40585407633267, 329.0882491805651, 82.15794538779275, 359.0960126203566, 810.0603600895039, 118.07407158112466, 320.89762608240096, 633.1456780002605, 84.31353413007531, 318.40311891944816, 95.05864907392963, 954.2747052547861, 343.3060371479956, 114.34955504361076, 446.9197312099248, 685.0184856008972, 889.3418136601408, 533.3413786546447, 919.4953129652058, 462.95721006271674, 150.80241400478442, 227.27802988738378, 1159.0570935168198, 492.17441354997607, 743.7432339304984, 457.8717317660215, 878.993123329884, 3333.8445588907953, 806.6144079755788, 1162.312560018986, 1138.0416596371547, 3546.007758889685, 2443.4616506089756, 603.4871604402862, 1411.9755311515423, 1182.8136060803342, 2056.3141404968546, 2123.315333842254, 4170.470146682443, 4633.936049563075, 9198.66523939271, 1442.848925665292, 3499.472487241769, 1227.138692430988, 2157.890919136487, 1542.5177410140325, 3321.6964554347232, 1131.0987120010184, 4524.944868651901, 1873.1959536391735, 27.50363379017104, 66.14381220303218, 15.519665594155697, 20.25404077065324, 14.53705824669656, 16.397376152458992, 13.560761273394899, 32.2464615112127, 12.281053094682303, 16.80568545721634, 14.593807153109744, 14.269459620636571, 20.558656923900138, 11.747100512858728, 14.674015458272462, 18.171329427897902, 11.605119045292739, 11.329532501740177, 11.301070729887984, 17.250357866599707, 13.981405312001003, 11.74570399375345, 10.78365831672884, 10.76646497371421, 14.43557783605419, 10.967398126474224, 16.45336540041218, 11.078940307639973, 24.933380863464482, 9.603383727198104, 23.885707420767417, 31.54738409614801, 229.29600642434997, 24.086710620914953, 214.86874970769344, 136.51077919983945, 145.95582365416269, 60.75523358345751, 58.34309162479273, 67.15475938181072, 38.98331403691474, 223.6926451061925, 53.68100193261188, 33.536262599210254, 539.6146514207178, 45.39895647918052, 100.12942623921462, 141.98631998147232, 75.73641707852535, 44.04116413476327, 4777.717831596382, 327.07060935266463, 190.37809441579248, 96.77824582401092, 39.38300887812614, 254.43658034574722, 1391.2076711819536, 1248.6923711959762, 4524.944868651901, 53.486246774122364, 743.2287339322558, 367.11619158801255, 468.8472294583898, 1374.8146466604048, 647.3367592239383, 3546.007758889685, 4170.470146682443, 504.99204808141013, 9198.66523939271, 913.5585270173647, 491.7504092506267, 1529.2069844414632, 991.4938323638787, 1278.89777615898, 4633.936049563075, 3499.472487241769, 1508.2462676319412, 448.1390957514295, 1233.1991958757117, 1661.4130370560579, 1873.1959536391735, 1358.5901600019095, 1446.9008753087207, 3321.6964554347232, 3333.8445588907953, 3019.48843136809, 2157.890919136487, 1378.2208478394546, 1608.750573456207, 1750.3505486978224, 2056.3141404968546, 1442.848925665292, 1542.5177410140325, 2443.4616506089756, 31.186797850768606, 45.91703745808222, 20.3877855609352, 22.531136439489348, 16.868119359162367, 14.39062953607824, 18.33531471132671, 12.63857028297292, 25.62087865534279, 20.920207883871743, 30.236200312709204, 14.237161165275372, 19.221816780976965, 15.801598360388645, 14.274926544345949, 25.184250458803167, 10.513259978756897, 34.4387273458026, 11.330885000306294, 66.90574694390105, 11.508301385861941, 9.78697804371031, 10.148754642380876, 9.997794452427609, 13.364621047147418, 10.48007378831142, 16.052354455886547, 10.267516117390407, 9.895293267524815, 10.683612229298761, 62.60890815885682, 29.663012452434998, 53.5878847638991, 28.90751925346929, 298.9070428730074, 27.8452480921459, 77.8894495082216, 34.662439562792905, 41.912800618333506, 54.642528718647426, 49.66043273331041, 586.6650701079842, 833.3472604206929, 141.2438783204782, 128.33655688290605, 56.072179324716316, 327.71014656541985, 194.94025180369937, 107.44039699975204, 372.7550265508533, 601.8659391649421, 117.80964067827199, 555.2841941628249, 657.03967976939, 600.1290197336973, 190.4160028561677, 115.18402402093002, 549.3621944541854, 464.9353453245685, 787.0270499266503, 1233.1991958757117, 472.2218572105447, 437.3497408081256, 621.452575066277, 362.1851714602299, 9198.66523939271, 551.3078511669129, 297.09006396086505, 1446.9008753087207, 3019.48843136809, 4633.936049563075, 1750.3505486978224, 419.39038161692696, 3321.6964554347232, 1391.7342614580198, 1248.6923711959762, 1529.2069844414632, 4524.944868651901, 4777.717831596382, 4170.470146682443, 3499.472487241769, 2443.4616506089756, 2123.315333842254, 1391.2076711819536, 1378.2208478394546, 1608.750573456207, 2056.3141404968546, 2157.890919136487, 3333.8445588907953, 1440.199638063174, 1873.1959536391735, 30.48373235391214, 28.79789606486551, 22.734988779456803, 17.05281868650076, 18.98368258371191, 25.746332459690453, 15.512217656436066, 16.960579084130107, 24.224656882467087, 25.197935327919282, 26.691946211001014, 16.034500541066183, 12.214184016450583, 15.108882322072906, 28.67996482850059, 21.312435815182933, 14.61145143343307, 26.225146677140785, 10.993397467570668, 10.815329078509784, 9.492496771460889, 14.647877431526977, 13.743707928752562, 11.83165385880133, 13.93379513451292, 14.700968071550376, 10.888196339382093, 17.700922401192447, 8.753900400779386, 27.645183545483633, 33.6798756681745, 35.72826090846512, 72.16642950387488, 134.73626528891967, 22.69749963596376, 50.27247141243224, 105.19102694613028, 875.0061274526331, 96.5746758410287, 24.91079442078742, 177.2484424456685, 214.16756040698894, 144.31182451129132, 391.506567597786, 110.01572455045094, 116.4709071284789, 80.29280862673542, 76.65478585750247, 51.52046589843058, 319.6497111035134, 76.83234664418458, 61.84108687024258, 166.66246061757806, 384.1311947781294, 109.05597196427507, 360.8180678467607, 674.3189021174874, 3321.6964554347232, 884.4632579687376, 9198.66523939271, 135.2582950585458, 429.3990654547311, 3019.48843136809, 597.5881693148339, 862.7123903932871, 3333.8445588907953, 1661.4130370560579, 595.4012825456017, 1411.9755311515423, 1227.138692430988, 1019.627619818938, 767.9920500812358, 1182.8136060803342, 4633.936049563075, 2157.890919136487, 1391.7342614580198, 4170.470146682443, 1378.2208478394546, 2123.315333842254, 1608.750573456207, 2443.4616506089756, 1542.5177410140325, 3499.472487241769, 4524.944868651901, 1750.3505486978224, 1131.0987120010184, 1398.660941635093, 1358.5901600019095, 2056.3141404968546, 25.465657234054483, 28.60316064129562, 18.650014773712474, 15.394923922734288, 15.61376577839291, 13.768262468847015, 14.53495141556666, 12.189041141637802, 13.730697855406904, 13.42241620760821, 10.970183238819228, 10.709509755268474, 11.983507025913635, 10.49262851655611, 14.147118737020683, 33.953848582063344, 10.183399297080586, 10.556501566032251, 12.388677383322976, 9.35805271024942, 11.156986332254544, 11.986116443129923, 11.97626172304213, 23.741472537017344, 9.040234865598284, 9.507332416514327, 11.050485438700129, 18.11309279109086, 8.225943950648691, 10.25603779812903, 13.73388831738042, 25.88706530947409, 34.684985930540336, 14.111001486161173, 31.592673547411017, 47.6148379156298, 39.725385377358705, 20.658356043899744, 14.236232524560759, 35.8344301556256, 82.17827275606398, 102.05365524780055, 247.07997997743175, 17.524384672364906, 751.6780875966109, 24.601189875691116, 31.887962372519663, 1278.89777615898, 123.16594776629816, 9198.66523939271, 3019.48843136809, 4524.944868651901, 3499.472487241769, 369.9077910626666, 4777.717831596382, 40.669412010013716, 705.145621440241, 569.1288414197329, 3321.6964554347232, 391.506567597786, 2123.315333842254, 1041.8845351926193, 1398.660941635093, 4633.936049563075, 915.725317343398, 3333.8445588907953, 461.27847077305006, 2157.890919136487, 4170.470146682443, 862.7123903932871, 1529.2069844414632, 2056.3141404968546, 1873.1959536391735, 2443.4616506089756, 3546.007758889685, 1661.4130370560579, 1440.199638063174, 1508.2462676319412, 1023.8535004483588, 969.2659779371324, 1411.9755311515423, 1608.750573456207, 1391.2076711819536], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.8957, -8.9426, -8.8863, -8.8813, -9.1321, -7.729, -8.913, -8.8053, -9.1049, -9.2754, -7.1778, -9.3591, -8.1416, -9.4404, -9.4373, -6.7301, -9.0767, -9.0789, -9.2478, -9.2481, -9.4206, -9.3088, -9.2939, -9.5036, -7.3045, -9.0593, -9.3883, -9.3532, -9.1054, -9.313, -7.352, -8.2779, -8.6495, -6.7842, -6.2033, -7.7209, -8.5333, -5.6869, -7.3558, -7.442, -8.0522, -7.7959, -8.6806, -8.3299, -6.7214, -7.925, -6.3134, -7.6464, -6.2411, -5.4779, -7.3097, -6.3625, -5.7231, -7.6323, -6.3869, -7.524, -5.3873, -6.3513, -7.3633, -6.1375, -5.7587, -5.5638, -6.0331, -5.5692, -6.1867, -7.1329, -6.7937, -5.4591, -6.168, -5.8383, -6.2292, -5.7121, -4.7183, -5.8146, -5.5347, -5.5713, -4.7687, -5.0776, -6.0812, -5.5638, -5.6889, -5.3723, -5.3818, -5.0106, -4.9999, -4.6715, -5.6233, -5.2187, -5.7258, -5.5047, -5.6441, -5.385, -5.8011, -5.5841, -5.728, -8.4926, -7.6294, -9.0864, -8.8227, -9.1552, -9.035, -9.2267, -8.3638, -9.3317, -9.0185, -9.1598, -9.1842, -8.8196, -9.3797, -9.1573, -8.9439, -9.393, -9.4179, -9.4214, -9.0004, -9.2115, -9.3858, -9.4716, -9.4734, -9.1828, -9.4581, -9.0531, -9.4504, -8.6413, -9.596, -8.6853, -8.4116, -6.4714, -8.6828, -6.5458, -6.9866, -6.9263, -7.7833, -7.825, -7.6936, -8.2181, -6.5557, -7.9244, -8.3753, -5.7516, -8.0888, -7.3458, -7.0271, -7.6199, -8.1277, -3.8419, -6.302, -6.8111, -7.4283, -8.2424, -6.5906, -5.1326, -5.2435, -4.1508, -7.9786, -5.725, -6.3289, -6.121, -5.238, -5.883, -4.4776, -4.3485, -6.099, -3.7269, -5.6329, -6.129, -5.252, -5.5956, -5.4049, -4.4413, -4.7179, -5.3851, -6.2471, -5.5951, -5.4097, -5.3347, -5.5379, -5.5721, -5.1271, -5.1374, -5.2083, -5.4255, -5.6625, -5.6121, -5.5819, -5.5545, -5.6629, -5.6759, -5.6729, -8.3025, -7.922, -8.7381, -8.6423, -8.9369, -9.0998, -8.8651, -9.2378, -8.5329, -8.7378, -8.3733, -9.1284, -8.8295, -9.0263, -9.129, -8.5613, -9.4363, -8.2504, -9.3642, -7.5886, -9.3512, -9.5135, -9.4775, -9.4927, -9.2043, -9.4482, -9.0238, -9.472, -9.5101, -9.434, -7.6879, -8.4258, -7.8474, -8.4531, -6.187, -8.4907, -7.4945, -8.2823, -8.101, -7.8531, -7.9523, -5.614, -5.2892, -6.9775, -7.0709, -7.8525, -6.2384, -6.7113, -7.2655, -6.1587, -5.7616, -7.207, -5.8537, -5.7097, -5.8015, -6.811, -7.2505, -5.9541, -6.1411, -5.7218, -5.3606, -6.1455, -6.2125, -5.9487, -6.3812, -3.925, -6.0879, -6.5595, -5.4213, -4.9037, -4.6166, -5.3062, -6.3223, -4.935, -5.529, -5.6167, -5.4959, -4.8733, -5.0003, -5.1259, -5.241, -5.4343, -5.52, -5.7245, -5.7332, -5.7131, -5.6563, -5.6667, -5.6519, -5.8234, -5.8281, -7.8165, -7.8788, -8.1312, -8.421, -8.3144, -8.0115, -8.5184, -8.4341, -8.0785, -8.0393, -7.9825, -8.4963, -8.7728, -8.5606, -7.9284, -8.2259, -8.6051, -8.0223, -8.8929, -8.9096, -9.0418, -8.6087, -8.673, -8.8253, -8.6626, -8.6093, -8.9108, -8.4288, -9.1419, -7.9926, -7.7985, -7.7456, -7.0759, -6.4819, -8.1972, -7.4535, -6.777, -4.8408, -6.8919, -8.1311, -6.3754, -6.2416, -6.6282, -5.8416, -6.9199, -6.8875, -7.1871, -7.225, -7.5534, -6.1414, -7.2597, -7.4414, -6.7316, -6.1993, -7.0674, -6.2736, -5.8674, -4.88, -5.7302, -4.259, -6.9516, -6.2655, -5.1336, -6.0972, -5.8894, -5.1282, -5.5597, -6.1486, -5.7125, -5.7863, -5.8871, -6.0414, -5.8281, -5.2021, -5.554, -5.7569, -5.2637, -5.7758, -5.6032, -5.7404, -5.5982, -5.7775, -5.4974, -5.5671, -5.8556, -5.9645, -5.9648, -5.9988, -5.9862, -7.886, -7.7752, -8.2084, -8.4115, -8.403, -8.5306, -8.4794, -8.6563, -8.5373, -8.5651, -8.7689, -8.7936, -8.6822, -8.8188, -8.5224, -7.6511, -8.8561, -8.8238, -8.664, -8.9449, -8.7694, -8.6977, -8.7004, -8.0171, -8.9828, -8.9327, -8.7836, -8.2922, -9.0821, -8.8625, -8.5751, -7.9576, -7.6754, -8.5503, -7.7816, -7.4134, -7.6116, -8.2291, -8.5616, -7.7958, -7.1309, -6.9912, -6.3117, -8.4005, -5.5523, -8.1539, -7.9638, -5.3832, -7.032, -4.0155, -4.805, -4.5612, -4.7649, -6.3183, -4.6681, -7.8157, -5.9618, -6.1408, -5.0758, -6.4112, -5.3843, -5.8208, -5.6502, -4.9703, -5.9648, -5.2807, -6.3772, -5.5554, -5.2078, -6.0538, -5.7836, -5.6596, -5.707, -5.6374, -5.4665, -5.8206, -5.8887, -5.9213, -6.0695, -6.1165, -6.0582, -6.0415, -6.0855], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2439, 1.2279, 1.2223, 1.2207, 1.22, 1.2174, 1.2158, 1.2127, 1.2123, 1.2115, 1.2099, 1.2084, 1.2065, 1.2056, 1.2054, 1.2051, 1.2048, 1.2047, 1.204, 1.2039, 1.2038, 1.2038, 1.2031, 1.202, 1.2015, 1.1998, 1.1987, 1.1983, 1.1975, 1.1969, 1.196, 1.1908, 1.1935, 1.1586, 1.1459, 1.1739, 1.1885, 1.109, 1.1572, 1.1541, 1.1716, 1.1633, 1.1899, 1.1789, 1.1226, 1.1657, 1.0984, 1.1531, 1.0835, 1.0332, 1.1271, 1.0746, 1.0343, 1.1413, 1.058, 1.1296, 0.9599, 1.0183, 1.1056, 0.9683, 0.9201, 0.8539, 0.8959, 0.8151, 0.8838, 1.0593, 0.9883, 0.6937, 0.8413, 0.7582, 0.8524, 0.7173, 0.378, 0.7007, 0.6153, 0.5998, 0.2659, 0.3294, 0.7242, 0.3917, 0.4436, 0.2072, 0.1656, -0.1382, -0.2329, -0.5901, 0.3105, -0.1709, 0.37, 0.0266, 0.2229, -0.2851, 0.3762, -0.7933, -0.0553, 1.4012, 1.387, 1.3796, 1.3771, 1.3763, 1.376, 1.3743, 1.371, 1.3684, 1.368, 1.3678, 1.3659, 1.3653, 1.3649, 1.3648, 1.3644, 1.3637, 1.3629, 1.3619, 1.3599, 1.359, 1.3589, 1.3586, 1.3583, 1.3557, 1.3552, 1.3545, 1.3528, 1.3507, 1.35, 1.3496, 1.3451, 1.3017, 1.3438, 1.2924, 1.3051, 1.2986, 1.318, 1.3168, 1.3076, 1.3269, 1.2422, 1.3007, 1.3203, 1.1657, 1.3039, 1.2559, 1.2253, 1.261, 1.2954, 0.8946, 1.116, 1.1481, 1.2075, 1.2924, 1.0785, 0.8376, 0.8348, 0.6401, 1.2502, 0.8722, 0.9736, 0.9369, 0.7441, 0.8523, 0.557, 0.5239, 0.8846, 0.3545, 0.758, 0.8812, 0.6236, 0.7134, 0.6495, 0.3258, 0.3299, 0.5044, 0.856, 0.4957, 0.383, 0.3381, 0.456, 0.3589, -0.0271, -0.0411, -0.0129, 0.1058, 0.3171, 0.2128, 0.1587, 0.025, 0.2709, 0.1911, -0.2659, 1.4657, 1.4593, 1.4552, 1.4509, 1.4459, 1.4418, 1.4342, 1.4336, 1.4319, 1.4297, 1.4259, 1.4239, 1.4226, 1.4218, 1.4206, 1.4206, 1.4193, 1.4186, 1.4164, 1.4163, 1.4139, 1.4136, 1.4133, 1.4132, 1.4113, 1.4105, 1.4085, 1.4072, 1.406, 1.4055, 1.3834, 1.3924, 1.3795, 1.391, 1.321, 1.3908, 1.3584, 1.3803, 1.3715, 1.3543, 1.3507, 1.2197, 1.1935, 1.2802, 1.2826, 1.329, 1.1776, 1.2241, 1.2658, 1.1286, 1.0465, 1.2321, 1.035, 1.0107, 1.0095, 1.148, 1.2112, 0.9453, 0.9252, 0.8181, 0.7303, 0.9052, 0.9149, 0.8274, 0.9348, 0.1563, 0.8079, 0.9547, 0.5097, 0.2916, 0.1504, 0.4344, 0.847, 0.1649, 0.4409, 0.4616, 0.3797, -0.0825, -0.2639, -0.2535, -0.1932, -0.0273, 0.0275, 0.2458, 0.2465, 0.1119, -0.0768, -0.1354, -0.5556, 0.1122, -0.1554, 1.9745, 1.9691, 1.9531, 1.9508, 1.9502, 1.9484, 1.9482, 1.9431, 1.9424, 1.9421, 1.9414, 1.9371, 1.9328, 1.9323, 1.9236, 1.923, 1.9212, 1.9192, 1.918, 1.9176, 1.9159, 1.9152, 1.9146, 1.9121, 1.9113, 1.911, 1.9097, 1.9058, 1.8968, 1.8961, 1.8928, 1.8866, 1.8533, 1.8229, 1.8887, 1.8372, 1.7754, 1.5931, 1.746, 1.8618, 1.6552, 1.5998, 1.608, 1.3966, 1.5877, 1.563, 1.6354, 1.6439, 1.7128, 1.2995, 1.6068, 1.6422, 1.3607, 1.0579, 1.449, 1.0462, 0.8271, 0.2199, 0.693, -0.1777, 1.3494, 0.8803, 0.0617, 0.7181, 0.5587, -0.0319, 0.2331, 0.6704, 0.243, 0.3094, 0.3938, 0.523, 0.3044, -0.4351, -0.0227, 0.213, -0.3913, 0.2039, -0.0557, 0.0846, -0.1912, 0.0896, -0.4496, -0.7763, -0.115, 0.2128, 0.0001, -0.0049, -0.4067, 2.0849, 2.0795, 2.0739, 2.0627, 2.057, 2.0552, 2.0522, 2.0513, 2.0513, 2.0461, 2.0441, 2.0434, 2.0425, 2.0387, 2.0363, 2.0321, 2.0314, 2.0276, 2.0274, 2.0271, 2.0268, 2.0267, 2.0249, 2.0238, 2.0237, 2.0234, 2.0221, 2.0194, 2.0187, 2.0178, 2.0132, 1.9968, 1.9864, 2.011, 1.9736, 1.9316, 1.9146, 1.9509, 1.9908, 1.8335, 1.6684, 1.5915, 1.3868, 1.9441, 1.0336, 1.8515, 1.7822, 0.6712, 1.3627, 0.0658, 0.3903, 0.2296, 0.2829, 0.9766, 0.0683, 1.687, 0.6879, 0.7232, 0.0242, 0.827, 0.1632, 0.4386, 0.3147, -0.2033, 0.4237, -0.1844, 0.697, -0.0241, -0.3354, 0.3943, 0.092, -0.0801, -0.0342, -0.2304, -0.4319, -0.0278, 0.0469, -0.0318, 0.2074, 0.2151, -0.1028, -0.2165, -0.1153]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 5, 4, 1, 4, 1, 3, 2, 3, 5, 3, 5, 1, 2, 3, 4, 5, 2, 5, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 2, 1, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 2, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 1, 2, 3, 5, 5, 4, 1, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 5, 1, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 1, 2, 5, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 5, 1, 1, 2, 5, 1, 2, 3, 5, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 3, 1, 3, 2, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 2, 5, 2, 5, 2, 1, 2, 3, 4, 5, 4, 2, 5, 1, 2, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 3, 4, 2, 4, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 5, 1, 2, 3, 4, 5, 1, 4, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 5, 3, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 2, 3, 5, 1, 3, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 5, 5, 2, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 3, 5, 2, 3, 5, 1, 2, 3, 4, 5, 3, 4, 2, 3, 1, 2, 3, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 4, 1, 1, 2, 3, 4, 1, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 5, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 3, 2, 3, 3, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 2, 5, 1, 2, 4, 5, 3, 1, 5, 3, 5, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 2, 5], \"Freq\": [0.14935106748053986, 0.2090914944727558, 0.27058899284709576, 0.12299499674867989, 0.24774706487948378, 0.3329698555516223, 0.16813329339735383, 0.2303002254098208, 0.12810155687417435, 0.14128848184651582, 0.35601232542568856, 0.1588815336610511, 0.16378528469997242, 0.20007304238799026, 0.12063227555746471, 0.8962993860707952, 0.9270309455175071, 0.9733590969312544, 0.9617385452576834, 0.9481827311758828, 0.9465056905126858, 0.8875005993714686, 0.9006496827673671, 0.9541917549429038, 0.06742403534391607, 0.910224477142867, 0.033712017671958035, 0.9560134445613626, 0.04780067222806813, 0.23259405912343417, 0.3768612603518933, 0.20683205890406645, 0.13469845828983687, 0.04931582899136104, 0.9380844156060818, 0.8737510982096629, 0.9631955140218951, 0.8134342429777631, 0.01570336376404948, 0.009422018258429688, 0.1570336376404948, 0.006281345505619792, 0.9005922937778514, 0.2070494314377205, 0.18719537636835004, 0.20137684427504324, 0.16734132129897958, 0.2382486608324455, 0.9478575753569554, 0.9256359357619405, 0.04014324003916654, 0.04014324003916654, 0.883151280861664, 0.08028648007833308, 0.018696395060642364, 0.8413377777289064, 0.07478558024256945, 0.018696395060642364, 0.0560891851819271, 0.5678053794618884, 0.16612646473339093, 0.12273522394481867, 0.07190548473534832, 0.07066573499853196, 0.09372090138570782, 0.5623254083142469, 0.14058135207856173, 0.0825636512207426, 0.12049830178162434, 0.9275169897187663, 0.05796981185742289, 0.9771149027273566, 0.025172820615856007, 0.025172820615856007, 0.10069128246342403, 0.8055302597073922, 0.12304665547856473, 0.48714372619792434, 0.22592172809179098, 0.07766059403155315, 0.08572922717768855, 0.8628291451089332, 0.11353015067222805, 0.07271687781623767, 0.03635843890811884, 0.11816492645138621, 0.6635415100731687, 0.11816492645138621, 0.11162449026336883, 0.08371836769752662, 0.05581224513168442, 0.02790612256584221, 0.7534653092777396, 0.21090087581388406, 0.036678413185023316, 0.05501761977753498, 0.5776850076641172, 0.11920484285132578, 0.16968029645316127, 0.27994392344124247, 0.3456450483305137, 0.12054728131857585, 0.08398317703237275, 0.9643324792847285, 0.053574026626929366, 0.9453663756471877, 0.062296157410932994, 0.9344423611639949, 0.926607256682851, 0.04483919748352009, 0.029892798322346727, 0.9266767479927486, 0.014946399161173364, 0.8509661677731205, 0.9481172568905605, 0.9429716519874047, 0.05238731399930026, 0.031993363845463973, 0.6100068039868465, 0.15356814645822708, 0.15356814645822708, 0.05118938215274236, 0.9492710584014028, 0.007079952858070277, 0.13451910430333527, 0.8071146258200116, 0.007079952858070277, 0.042479717148421664, 0.03459307563654002, 0.03459307563654002, 0.8994199665500405, 0.03459307563654002, 0.021010820663347217, 0.751136838714663, 0.052527051658368046, 0.15758115497510414, 0.015758115497510414, 0.034585561569043355, 0.31309034683555037, 0.577032790388776, 0.007281170856640707, 0.06917112313808671, 0.036627144239506915, 0.879051461748166, 0.05127800193530968, 0.014650857695802766, 0.014650857695802766, 0.029818468800502207, 0.8945540640150662, 0.029818468800502207, 0.029818468800502207, 0.029818468800502207, 0.6617573852644761, 0.07207258651395285, 0.12448901306955493, 0.10264883533805406, 0.03931231991670155, 0.921052896296976, 0.04186604074077163, 0.04186604074077163, 0.02903707764688582, 0.9291864847003463, 0.02903707764688582, 0.02903707764688582, 0.06301991334764179, 0.10503318891273632, 0.7037223657153333, 0.06301991334764179, 0.06301991334764179, 0.792866503622873, 0.048961875721731205, 0.0505412910675935, 0.06317661383449187, 0.04422362968414431, 0.9511797501636989, 0.2589918717807916, 0.28121101359576567, 0.2506596936001763, 0.08332178180615278, 0.12567702089094712, 0.8550760561114729, 0.055801508460249664, 0.014770987533595499, 0.049236625111985, 0.022977091718926333, 0.6899895915225651, 0.07499886864375707, 0.07312389692766315, 0.11062333124954168, 0.05062423633453603, 0.055978095466889595, 0.027989047733444797, 0.8956495274702335, 0.027989047733444797, 0.9179282806121064, 0.042120386527870805, 0.9266485036131576, 0.9297094160523739, 0.9530500373877908, 0.013199779398623025, 0.18479691158072237, 0.7391876463228895, 0.022799618961257952, 0.04079931814119844, 0.0178341561188296, 0.053502468356488794, 0.8382053375849912, 0.0178341561188296, 0.0713366244753184, 0.028751997871041404, 0.5520383591239949, 0.286082378816862, 0.025876798083937263, 0.10710119206962923, 0.8940268141288941, 0.02341865194181455, 0.07360147753141716, 0.8397259481993503, 0.02341865194181455, 0.03680073876570858, 0.05078332146203352, 0.8633164648545699, 0.05078332146203352, 0.02539166073101676, 0.9593110182367175, 0.02945174234323074, 0.02945174234323074, 0.913004012640153, 0.9817143052788847, 0.028830918426854372, 0.08649275528056312, 0.028830918426854372, 0.8649275528056312, 0.1749913870565662, 0.2417253905950872, 0.11122333923086834, 0.3084593941336082, 0.16312756420527355, 0.9246135672256285, 0.08701644823327195, 0.1907668288190962, 0.2828034567581339, 0.27778327705236816, 0.16231914381975732, 0.30028721579155737, 0.1951866902645123, 0.20519626412423086, 0.1351292471062008, 0.16444299912394808, 0.8326463939773922, 0.022278164387354974, 0.016708623290516228, 0.08354311645258115, 0.04455632877470995, 0.9472835235659026, 0.9442004776866117, 0.9123412780185542, 0.9268327555710564, 0.023764942450539905, 0.023764942450539905, 0.012838709302913294, 0.08987096512039305, 0.873032232598104, 0.012838709302913294, 0.03968579119623349, 0.9524589887096039, 0.9329834316136899, 0.02701319460859997, 0.21610555686879976, 0.630307874200666, 0.09724750059095989, 0.030614953889746634, 0.017363519090430293, 0.1475899122686575, 0.7553130804337178, 0.034727038180860585, 0.04340879772607573, 0.9298063899800824, 0.014085864048458883, 0.8169801148106152, 0.05634345619383553, 0.021128796072688322, 0.09155811631498273, 0.7925335340801828, 0.07036512685758632, 0.045675608661942, 0.053082464120635296, 0.037034277293466485, 0.9355396955106876, 0.05503174679474633, 0.43962970778058724, 0.15725216470613312, 0.1809245335866263, 0.183460858823822, 0.03889032030366733, 0.02055416443751088, 0.8769776826671309, 0.013702776291673921, 0.0068513881458369605, 0.08221665775004353, 0.8995739114741431, 0.014278950975780049, 0.04283685292734015, 0.028557901951560098, 0.1414867583128557, 0.327959050038004, 0.286601382223477, 0.16543067125810823, 0.07836189691173548, 0.030431834835031667, 0.5501755403070199, 0.35557196491458054, 0.018419268452782325, 0.04484691449373088, 0.11934961284827976, 0.01989160214137996, 0.8553388920793383, 0.01989160214137996, 0.952794893804758, 0.2425303686550059, 0.02771775641771496, 0.02078831731328622, 0.6721555931295877, 0.0346471955221437, 0.060742409500924945, 0.26505778691312704, 0.5715308530314301, 0.030371204750462472, 0.07454750256931697, 0.020578496247351124, 0.2492284545512525, 0.5601923978445584, 0.029724494579507182, 0.14176297414841887, 0.9210459868296011, 0.9347071991684084, 0.009074827176392315, 0.009074827176392315, 0.03629930870556926, 0.009074827176392315, 0.910687698435063, 0.1358123147467585, 0.04244134835836203, 0.7639442704505166, 0.04244134835836203, 0.008488269671672407, 0.9728552850937545, 0.9402289417213125, 0.9764265579361346, 0.07068577132834578, 0.9189150272684952, 0.04123865225159472, 0.394192999463773, 0.37236077180116406, 0.04245155378840632, 0.15039979056463956, 0.9468134840836717, 0.10068377830800057, 0.020136755661600114, 0.8658804934488049, 0.9192521291659472, 0.06339669856316878, 0.8785676628599538, 0.10423684135626571, 0.9757658695656988, 0.4082668105000489, 0.22817306774453833, 0.08474999659082852, 0.18416826182237736, 0.09452884235130873, 0.9321716029875484, 0.07086669227416012, 0.9212669995640815, 0.048406562355444174, 0.09681312471088835, 0.822911560042551, 0.018923634941265997, 0.45416723859038394, 0.14598232668976627, 0.06217765766415971, 0.3189984175813411, 0.055208683107495694, 0.8833389297199311, 0.7567823431293643, 0.035199178750202995, 0.035199178750202995, 0.0659984601566306, 0.1011976389068336, 0.8482761473186846, 0.01749022984162236, 0.01749022984162236, 0.03498045968324472, 0.07870603428730064, 0.010588243478468852, 0.3472943860937784, 0.5527063095760741, 0.014823540869856393, 0.07411770434928197, 0.9809795154173963, 0.9177284445876434, 0.0874894698124802, 0.5843794251589586, 0.1720486703010974, 0.027628253624993746, 0.1285132403465618, 0.042690204126635774, 0.5100932082823659, 0.3469947361062446, 0.02846013608442385, 0.07115034021105962, 0.024402623311054635, 0.5775287516949597, 0.25012688893831, 0.03457038302399407, 0.11591246072750952, 0.21748386280747595, 0.5026132080266418, 0.07855604409099466, 0.11783406613649199, 0.0836476395413369, 0.03489149100069762, 0.24091743786195977, 0.6380158354413279, 0.004984498714385374, 0.07975197943016599, 0.927329085018102, 0.03591277034741387, 0.8978192586853467, 0.03591277034741387, 0.9005527972376207, 0.9354828335053711, 0.9110366016383219, 0.9371696743212251, 0.9370876711677012, 0.009465532031996982, 0.009465532031996982, 0.03786212812798793, 0.009465532031996982, 0.01866093435868692, 0.05598280307606076, 0.8957248492169722, 0.01866093435868692, 0.01866093435868692, 0.5140409360642538, 0.2187969112478619, 0.1098378068513363, 0.07205360129447662, 0.08523413811663696, 0.12751536576663383, 0.45304419379826577, 0.20619035747013753, 0.06210020412551838, 0.15094106554351977, 0.34673690461892276, 0.2450987376268402, 0.2071667901369721, 0.08996679853366159, 0.11087800035499915, 0.2455358662175245, 0.40331184275183224, 0.17384131153096216, 0.09135660647351253, 0.08584164072839236, 0.9841314590911615, 0.06395367030013775, 0.20532494148991592, 0.5823149979959911, 0.023561878531629697, 0.12117537530552416, 0.9132691893143217, 0.03970735605714442, 0.019974148211155146, 0.8389142248685162, 0.1098578151613533, 0.019974148211155146, 0.019974148211155146, 0.9558317627581083, 0.13309119994778248, 0.009506514281984462, 0.02851954284595339, 0.7985471996866949, 0.02851954284595339, 0.06802273123327307, 0.88429550603255, 0.5831341037776958, 0.010413108996030283, 0.010413108996030283, 0.3904915873511356, 0.0078098317470227125, 0.037464484309047974, 0.9366121077261993, 0.6622875377645119, 0.07758546707258289, 0.06746562354137642, 0.11806484119740875, 0.075336612954537, 0.9438074617709495, 0.7806445882117361, 0.052431352939594215, 0.04951849999850565, 0.06116991176285992, 0.055344205880682784, 0.876550851939392, 0.8849327610329246, 0.1072778938491491, 0.03320506238187948, 0.03831353351755325, 0.546606411517093, 0.2733032057585465, 0.048511437166276185, 0.016170479055425395, 0.03234095811085079, 0.695330599383292, 0.21021622772053014, 0.9095233215105345, 0.9540674152764036, 0.0709776108266471, 0.18712279217934233, 0.5656700499214602, 0.1505585684201605, 0.02796087699231552, 0.3691934440175952, 0.1328315036677062, 0.23929204704844131, 0.11036735231213823, 0.14748203716046793, 0.9669797273490714, 0.9589013220009673, 0.8879075352149903, 0.8938097168975472, 0.009931219076639413, 0.019862438153278827, 0.06951853353647588, 0.009931219076639413, 0.9304591571380135, 0.054732891596353736, 0.9619455047469916, 0.9039076968622911, 0.056494231053893194, 0.9676714694435682, 0.14340177478468213, 0.235801532671348, 0.2997196447578229, 0.14373295671259134, 0.1771823314314202, 0.9656757239637133, 0.059382642017585655, 0.029691321008792827, 0.8907396302637848, 0.6542396173695114, 0.048763201294621965, 0.04063600107885164, 0.1909892050706027, 0.06501760172616262, 0.19954654829141863, 0.12748807251951746, 0.1358025120316599, 0.3852356973959332, 0.1524313910559448, 0.9116675910950247, 0.5213743883057593, 0.11958917487541344, 0.162606863679519, 0.12044952865149555, 0.07571113229522577, 0.026407375436394775, 0.8450360139646328, 0.03961106315459216, 0.09242581402738172, 0.5816196648557045, 0.13090585049458875, 0.16073249997436848, 0.05799626287734945, 0.06959551545281933, 0.8810775203245823, 0.022026938008114557, 0.08810775203245823, 0.21951857312878806, 0.03135979616125544, 0.721275311708875, 0.2119398956061037, 0.23241136279532965, 0.2640217165433991, 0.16858855332303704, 0.12282880313535556, 0.10849772415734608, 0.2967520534899598, 0.34776753968314905, 0.16741701807060685, 0.07903807720071569, 0.07472649297763083, 0.012454415496271803, 0.024908830992543606, 0.697447267791221, 0.19927064794034885, 0.21010093520827638, 0.295260190011631, 0.250504961209868, 0.14731929480580327, 0.09634806200379538, 0.900198543071134, 0.02960057785118581, 0.5718293448524531, 0.2798600087748476, 0.03363702028543842, 0.08611077193072235, 0.883791329146855, 0.9367360238832096, 0.039030667661800404, 0.7428627040054642, 0.10068922192845148, 0.049225841831687385, 0.05593845662691749, 0.05370091836184079, 0.9115992030086981, 0.01860406536752445, 0.01860406536752445, 0.0372081307350489, 0.01860406536752445, 0.930489930698727, 0.9524700482430303, 0.03023714438866763, 0.9024499853744825, 0.8825435965266334, 0.13359432192514742, 0.014843813547238602, 0.007421906773619301, 0.838675465418981, 0.014843813547238602, 0.07234533265838049, 0.9043166582297562, 0.020454601119836956, 0.17556865961193388, 0.7585247915272871, 0.01875005102651721, 0.028977351586435687, 0.027570566145119917, 0.3924751180658247, 0.4646451294456974, 0.018650677098169356, 0.0964969815079197, 0.023376036204066097, 0.08571213274824235, 0.8103692550742914, 0.03116804827208813, 0.05454408447615423, 0.8775318672910737, 0.5779339866454778, 0.16041081125396134, 0.07963657296295953, 0.08077423829100182, 0.10125221419576284, 0.018300763589272503, 0.07320305435709001, 0.8601358886958077, 0.018300763589272503, 0.018300763589272503, 0.9364359365767055, 0.8978200254308089, 0.02565200072659454, 0.07695600217978361, 0.04405771631407007, 0.04405771631407007, 0.8811543262814014, 0.08518066595021573, 0.09734933251453226, 0.0730119993858992, 0.10951799907884881, 0.6327706613444597, 0.9115618018679829, 0.26692348925301657, 0.33525590250178877, 0.19165106528366588, 0.09075398634602562, 0.11584479433580919, 0.11412668903313346, 0.855950167748501, 0.8991067520483331, 0.010334560368371645, 0.02066912073674329, 0.06200736221022987, 0.005167280184185823, 0.9436117758921181, 0.010256649737957806, 0.015384974606936708, 0.025641624344894514, 0.010256649737957806, 0.905920794293043, 0.6825684817765156, 0.09936123468898646, 0.09504118100685661, 0.08856110048366184, 0.034560429457038765, 0.1901995427698921, 0.3503042211774595, 0.1721426241524973, 0.1709388295780043, 0.11676807372581983, 0.20639376942018606, 0.24898295993546254, 0.1976575252119242, 0.16380457890490957, 0.1834611283734987, 0.02177840852456787, 0.9582499750809863, 0.8258085397364472, 0.0062325172810297905, 0.04051136232669364, 0.09972027649647665, 0.028046327764634057, 0.2059493473449798, 0.33385473148554623, 0.14308059920809124, 0.0780439632044134, 0.24063555321360797, 0.24399198453034288, 0.39582395316471386, 0.2247643553146365, 0.01922762921570637, 0.11602879699133153, 0.06931697348918144, 0.44598279169454474, 0.32762078979320663, 0.026157348486483562, 0.1314406761445799, 0.9049376206568082, 0.9467836330606337, 0.943951626136691, 0.9586482453241717, 0.9329763122177004, 0.0345546782302852, 0.1320033312749472, 0.0660016656374736, 0.20400514833400932, 0.5280133250997888, 0.0660016656374736, 0.9153345129803883, 0.024738770621091574, 0.024738770621091574, 0.024738770621091574, 0.024738770621091574, 0.9485349053633044, 0.8723337699863447, 0.008469259902780047, 0.11010037873614059, 0.008469259902780047, 0.9117932881328508, 0.4171460390107743, 0.15864297578678002, 0.1437701968067694, 0.17209929962583725, 0.10835881828293457, 0.15417883097453944, 0.18682846576914777, 0.5024416021170285, 0.0852518241859218, 0.0707408753883181, 0.9630559197340629, 0.13586833655192615, 0.03881952472912176, 0.03881952472912176, 0.7569807322178742, 0.03881952472912176, 0.9260422840971436, 0.03307293871775513, 0.2645667118383974, 0.1371827394717616, 0.5879260263075498, 0.8876638966685457, 0.019979573236912605, 0.019979573236912605, 0.022833797985042977, 0.04852182071821633, 0.04128025444702018, 0.9494458522814642, 0.9241848857311226, 0.04864130977532224, 0.031652908339628284, 0.031652908339628284, 0.06330581667925657, 0.8546285251699636, 0.9365126182176882, 0.06651783632521235, 0.3219463278140278, 0.2620802751213367, 0.013303567265042471, 0.3365802518055745, 0.2233522407150155, 0.33082027537789255, 0.2602539152679311, 0.08739870288848432, 0.09797286694165898, 0.8885324438851722, 0.01217167731349551, 0.02434335462699102, 0.060858386567477545, 0.23346206075739726, 0.004669241215147945, 0.023346206075739725, 0.6677014937661562, 0.07003861822721918, 0.02682727069445902, 0.21730089262511804, 0.6921435839170427, 0.010730908277783608, 0.050971814319472133, 0.06388867203770505, 0.8944414085278709, 0.03194433601885253, 0.15260808144215782, 0.30329656437560926, 0.2812211815254858, 0.07678394034825552, 0.1862010553445196, 0.9479744564661274, 0.04213219806516122, 0.977409257243483, 0.02385905941018362, 0.04771811882036724, 0.882785198176794, 0.04771811882036724, 0.9529411366866674, 0.9119651675292597, 0.01628509227730821, 0.01628509227730821, 0.03257018455461642, 0.03257018455461642, 0.9131033812911505, 0.9433640160889958, 0.025648884485051822, 0.20519107588041458, 0.7592069807575339, 0.005129776897010364, 0.005129776897010364, 0.9466377744788763, 0.970913848237819, 0.9151521741885875, 0.038131340591191144, 0.41110470294619283, 0.24135824495550676, 0.12996213189911904, 0.16709416958458162, 0.051277575851353084, 0.09110746066910384, 0.09110746066910384, 0.05206140609663077, 0.6767982792562001, 0.09110746066910384, 0.9520587565876177, 0.9433291688389395, 0.01612528493741777, 0.008062642468708884, 0.008062642468708884, 0.02418792740612665, 0.9182791977176309, 0.030609306590587696, 0.030609306590587696, 0.07037309914659833, 0.45742514445288907, 0.21424699073519934, 0.023457699715532774, 0.23457699715532773, 0.9288099691416359, 0.8868083146296873, 0.9096369006486772, 0.0323781797324523, 0.29949816252518374, 0.1537963537291484, 0.036425452199008834, 0.4816254235202279, 0.019651262382184318, 0.7035151932821986, 0.10611681686379532, 0.039302524764368636, 0.1296983317224165, 0.14753102401683768, 0.07376551200841884, 0.04917700800561256, 0.09835401601122512, 0.6393011040729633, 0.14057044418429904, 0.03885687075013144, 0.07657089236055313, 0.6651381993110734, 0.07771374150026288, 0.07334338074076366, 0.005641798518520282, 0.028208992592601408, 0.7052248148150352, 0.18053755259264903, 0.8447582090585866, 0.06077397187471845, 0.009116095781207768, 0.04558047890603884, 0.03950308171856699, 0.5642517557229456, 0.13286662137818597, 0.09490472955584713, 0.12078783761653271, 0.08713979713764146, 0.030439561895287157, 0.2633022103942339, 0.6148791502848006, 0.016741759042407937, 0.07457692664345354, 0.8731451667848625, 0.031559463859693826, 0.010519821286564607, 0.05259910643282304, 0.031559463859693826, 0.8660755579421846, 0.009362979004780374, 0.009362979004780374, 0.10299276905258412, 0.009362979004780374, 0.01861601561623821, 0.8702987300591363, 0.07911806636901239, 0.009308007808119105, 0.01861601561623821, 0.936013006216753, 0.9606907272016166, 0.010332900658464896, 0.795633350701797, 0.05166450329232448, 0.06199740395078937, 0.07233030460925427, 0.03176510896586078, 0.29478021120318804, 0.506971139095138, 0.012706043586344312, 0.15374312739476617, 0.8897131170866543, 0.1299060356386757, 0.09742952672900679, 0.1786207990031791, 0.12178690841125848, 0.47090937919019943, 0.11431453404363306, 0.5607591332140379, 0.1498447270571947, 0.04479893901709944, 0.12976244404952944, 0.36801949931678024, 0.41708876589235094, 0.08685824198434354, 0.05019729569225049, 0.07783400905090525, 0.8156368106686783, 0.03978716149603309, 0.019893580748016546, 0.08620551657473836, 0.03315596791336091, 0.9234169916758938, 0.03551603814138053, 0.028849671650734373, 0.028849671650734373, 0.8943398211727656, 0.028849671650734373, 0.028849671650734373, 0.6023584209733663, 0.14655595510289493, 0.044370151544913146, 0.16672420580512817, 0.04168105145128204, 0.041570575413307914, 0.013856858471102637, 0.013856858471102637, 0.8591252252083635, 0.06928429235551319, 0.895599675025503, 0.027416316582413357, 0.03655508877655114, 0.027416316582413357, 0.01827754438827557, 0.06010084554659053, 0.16313086648360287, 0.06010084554659053, 0.643937630856327, 0.07727251570275925, 0.9743471338529262, 0.054539560173583836, 0.9271725229509252, 0.9133667251723852, 0.04151666932601751, 0.8978930235033722, 0.17602958386299586, 0.01035468140370564, 0.01035468140370564, 0.7766011052779229, 0.02070936280741128, 0.9494744841643029, 0.9184836015094912, 0.35267017392122896, 0.28913767935453694, 0.11474746467657633, 0.14781029348169153, 0.09594703261092258, 0.2283749913240501, 0.053183217157655505, 0.04692636808028427, 0.4942910771123276, 0.1751917741663946, 0.15525849997525304, 0.036966309517917385, 0.029573047614333912, 0.5249215951544269, 0.25876416662542173, 0.02145971961803511, 0.3838905398337392, 0.522186510705521, 0.011922066454463951, 0.06199474556321255, 0.7080100905226795, 0.07153091636208514, 0.0948879502762354, 0.06715147250318197, 0.05985239940501001, 0.9382613100006637, 0.9722932514559989, 0.007412697170969412, 0.7672141571953341, 0.06300792595324, 0.022238091512908235, 0.14084124624841882, 0.0783164927116104, 0.19829069431237528, 0.61486778320392, 0.06498602586708097, 0.043324017244720646, 0.022352098333972382, 0.8270276383569781, 0.1117604916698619, 0.008940839333588952, 0.03129293766756133, 0.01528721889715483, 0.7307290632840009, 0.12229775117723864, 0.006114887558861932, 0.12841263873610057, 0.9337495579646459, 0.07276056834036376, 0.9458873884247289, 0.9816884636403563, 0.045055730917220586, 0.2703343855033235, 0.5117043725598623, 0.0418374644231334, 0.13033979301053097, 0.0198022920123049, 0.5782269267593031, 0.29505415098334303, 0.01782206281107441, 0.08713008485414156, 0.07628692691396212, 0.11595612890922243, 0.7262515442209194, 0.03661772491870182, 0.04272067907181879, 0.9103422833971551, 0.013387386520546399, 0.013387386520546399, 0.040162159561639196, 0.013387386520546399, 0.046920962421742624, 0.9384192484348525, 0.9138783437937832, 0.013083524858466164, 0.876596165517233, 0.06105644933950877, 0.0043611749528220545, 0.0479729244810426, 0.15632702816946253, 0.34059289238868296, 0.2618858211823611, 0.11316859271516724, 0.12806205784675023, 0.10500928321670766, 0.021001856643341532, 0.021001856643341532, 0.021001856643341532, 0.8190724090903198, 0.07024330336518254, 0.9131629437473732, 0.0406484403824759, 0.1625937615299036, 0.7723203672670421, 0.03486754624629994, 0.9414237486500983, 0.18203130378728602, 0.18994570829977672, 0.20351325889261793, 0.27022038264075376, 0.15376557338553354, 0.3920667221281091, 0.1829371866297127, 0.21772389997093322, 0.1117267381429789, 0.09535652010005158, 0.28963465875749794, 0.2655370551488741, 0.1955613215930626, 0.13207340439341908, 0.11724410986503517, 0.9364012837005243, 0.9665156706500564, 0.41153688354818757, 0.2291648535210024, 0.1283803106112422, 0.13107989658203933, 0.09988468091949451, 0.8776764105966187, 0.03558147610526832, 0.011860492035089442, 0.05930246017544721, 0.011860492035089442, 0.7366851454082112, 0.06916247453334558, 0.08383330246466131, 0.057635395444454646, 0.05239581404041332, 0.03291897474565157, 0.8888123181325924, 0.04937846211847736, 0.03291897474565157, 0.1826369983737913, 0.039136499651526706, 0.05218199953536894, 0.7044569937274807, 0.02609099976768447, 0.9184257601812773, 0.12440382273014657, 0.3421105125079031, 0.3725203358419389, 0.06496644075907654, 0.09537626409311237, 0.9224581345766264, 0.04010687541637506, 0.017139989879711017, 0.891279473744973, 0.017139989879711017, 0.06855995951884407, 0.9195892705393297, 0.9663912220589517, 0.05368840122549731, 0.07725866088297172, 0.8884746001541748, 0.9651466885362107, 0.9450583419313726, 0.03722994433843382, 0.1209973190999099, 0.7911363171917186, 0.03722994433843382, 0.009307486084608454, 0.15300580062357141, 0.18662071136662878, 0.24573658888028135, 0.23646351005461036, 0.17850676739416665, 0.9226343915229235, 0.9425236419829187, 0.9026134018525271, 0.4054614615034908, 0.1320586948408316, 0.1733270369785915, 0.1413440718218276, 0.14856603169593557, 0.9586125374081585, 0.028194486394357607, 0.22589709154880802, 0.16767619166509462, 0.21658174756741388, 0.3260370393487951, 0.06287857187441048, 0.2377501189202861, 0.33233580325035184, 0.18459925098858754, 0.08629872105039231, 0.15916684644062423, 0.38465565599259927, 0.3132691108264052, 0.13099084501369598, 0.10673328112227079, 0.06445581262578691, 0.05720259819966413, 0.6319525134439086, 0.18522746083700767, 0.04903079845685497, 0.07627013093288551, 0.6373061305883726, 0.09026690928128828, 0.09787978114838487, 0.10766775926322336, 0.06742829367999846, 0.4366802820584899, 0.14276086144219863, 0.08229743777256156, 0.26368770878147274, 0.07389974004066753, 0.930334634997655, 0.031011154499921836, 0.26692984644608725, 0.19140823135402352, 0.22526274846425898, 0.22786694208812325, 0.08854258321138503, 0.974826341866402, 0.017102216523971966, 0.875542525435743, 0.11177138622583953], \"Term\": [\" \\n\\n\", \" \\n\\n\", \" \\n\\n\", \" \\n\\n\", \" \\n\\n\", \"$\", \"$\", \"$\", \"$\", \"$\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2012\", \"250\", \"4.50\", \"accent\", \"accessories\", \"acrylic\", \"acts\", \"acura\", \"albeit\", \"ale\", \"ale\", \"ale\", \"alfredo\", \"alfredo\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"ami\", \"angeles\", \"anything\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appreciates\", \"area\", \"area\", \"area\", \"area\", \"area\", \"arepa\", \"arrogant\", \"artist\", \"artist\", \"artist\", \"artist\", \"asada\", \"asada\", \"asada\", \"asada\", \"asada\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"avec\", \"avec\", \"baba\", \"bagel\", \"bagel\", \"bagel\", \"bagel\", \"bar\", \"bar\", \"bar\", \"bar\", \"bar\", \"basil\", \"basil\", \"bathroom\", \"bathroom\", \"bathroom\", \"bathroom\", \"bathroom\", \"bay\", \"bay\", \"bay\", \"bay\", \"bay\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"best\", \"best\", \"best\", \"best\", \"best\", \"billing\", \"billing\", \"biryani\", \"bleu\", \"bleu\", \"blind\", \"boba\", \"boba\", \"boba\", \"boba\", \"bobbie\", \"boots\", \"bouncers\", \"bouncers\", \"breakfast\", \"breakfast\", \"breakfast\", \"breakfast\", \"breakfast\", \"breasts\", \"broth\", \"broth\", \"broth\", \"broth\", \"broth\", \"brulee\", \"brulee\", \"brulee\", \"brulee\", \"brunch\", \"brunch\", \"brunch\", \"brunch\", \"brunch\", \"burger\", \"burger\", \"burger\", \"burger\", \"burger\", \"burrito\", \"burrito\", \"burrito\", \"burrito\", \"burrito\", \"burritos\", \"burritos\", \"burritos\", \"burritos\", \"burritos\", \"business\", \"business\", \"business\", \"business\", \"business\", \"byob\", \"byob\", \"byob\", \"cajun\", \"cajun\", \"cajun\", \"cajun\", \"cake\", \"cake\", \"cake\", \"cake\", \"cake\", \"called\", \"called\", \"called\", \"called\", \"called\", \"calzone\", \"came\", \"came\", \"came\", \"came\", \"came\", \"car\", \"car\", \"car\", \"car\", \"car\", \"care\", \"care\", \"care\", \"care\", \"care\", \"cats\", \"cats\", \"cats\", \"cats\", \"cesar\", \"chains\", \"chains\", \"channels\", \"char\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"chewy\", \"chewy\", \"chewy\", \"chewy\", \"chewy\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chilli\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chorizo\", \"chorizo\", \"chorizo\", \"chorizo\", \"chunky\", \"church\", \"church\", \"church\", \"cirque\", \"clam\", \"clam\", \"clam\", \"clam\", \"clean\", \"clean\", \"clean\", \"clean\", \"clean\", \"coca\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"come\", \"come\", \"come\", \"come\", \"come\", \"company\", \"company\", \"company\", \"company\", \"company\", \"computers\", \"concoction\", \"coney\", \"contacted\", \"contacted\", \"contacted\", \"cookies\", \"cookies\", \"cookies\", \"cookies\", \"cox\", \"cox\", \"crackers\", \"cream\", \"cream\", \"cream\", \"cream\", \"cream\", \"creamy\", \"creamy\", \"creamy\", \"creamy\", \"creamy\", \"cuban\", \"curry\", \"curry\", \"curry\", \"curry\", \"curry\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"dans\", \"dans\", \"day\", \"day\", \"day\", \"day\", \"day\", \"de\", \"de\", \"de\", \"de\", \"de\", \"dealership\", \"dealership\", \"dealership\", \"dealership\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"dentist\", \"dentist\", \"dentist\", \"dentist\", \"designs\", \"desk\", \"desk\", \"desk\", \"desk\", \"desk\", \"dessert\", \"dessert\", \"dessert\", \"dessert\", \"dessert\", \"dishes\", \"dishes\", \"dishes\", \"dishes\", \"dishes\", \"dissatisfied\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"done\", \"donuts\", \"donuts\", \"donuts\", \"donuts\", \"donuts\", \"doughnuts\", \"dunkin\", \"earl\", \"ears\", \"ears\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"emailed\", \"enchiladas\", \"enchiladas\", \"enchiladas\", \"est\", \"est\", \"et\", \"et\", \"ethiopian\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"facials\", \"fe\", \"fe\", \"fi\", \"fi\", \"fi\", \"fish\", \"fish\", \"fish\", \"fish\", \"fish\", \"fishy\", \"fishy\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fixed\", \"fixed\", \"fixed\", \"fixed\", \"fixed\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flies\", \"floral\", \"food\", \"food\", \"food\", \"food\", \"food\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fried\", \"fried\", \"fried\", \"fried\", \"fried\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"fries\", \"fries\", \"fries\", \"fries\", \"fries\", \"frittata\", \"frosting\", \"frosting\", \"frosting\", \"froyo\", \"frustration\", \"gabi\", \"ganoush\", \"gel\", \"gel\", \"gel\", \"gel\", \"gel\", \"gelato\", \"gelato\", \"gelato\", \"gelato\", \"gelato\", \"going\", \"going\", \"going\", \"going\", \"going\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"got\", \"got\", \"got\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greatest\", \"green\", \"green\", \"green\", \"green\", \"green\", \"grub\", \"grub\", \"guacamole\", \"guacamole\", \"guacamole\", \"guacamole\", \"guacamole\", \"gumbo\", \"gym\", \"gym\", \"gym\", \"gym\", \"gym\", \"gyms\", \"gyms\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"harness\", \"harness\", \"he\", \"he\", \"he\", \"he\", \"he\", \"heartbeat\", \"help\", \"help\", \"help\", \"help\", \"help\", \"hesitation\", \"homes\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"hotels\", \"hotels\", \"hotels\", \"hotels\", \"hotels\", \"hotpot\", \"humor\", \"ice\", \"ice\", \"ice\", \"ice\", \"ice\", \"if\", \"if\", \"if\", \"if\", \"if\", \"ihop\", \"ikea\", \"india\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"interactive\", \"interactive\", \"introduced\", \"ipad\", \"ipad\", \"iphone\", \"it\", \"it\", \"it\", \"it\", \"it\", \"jessica\", \"jewelry\", \"jewelry\", \"jewelry\", \"job\", \"job\", \"job\", \"job\", \"job\", \"kids\", \"kids\", \"kids\", \"kids\", \"kids\", \"knife\", \"know\", \"know\", \"know\", \"know\", \"know\", \"le\", \"le\", \"le\", \"le\", \"left\", \"left\", \"left\", \"left\", \"left\", \"les\", \"les\", \"les\", \"library\", \"library\", \"library\", \"like\", \"like\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lobby\", \"lobby\", \"lobby\", \"lobby\", \"lobby\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lox\", \"lunch\", \"lunch\", \"lunch\", \"lunch\", \"lunch\", \"luxurious\", \"macaroni\", \"macaroni\", \"manager\", \"manager\", \"manager\", \"manager\", \"manager\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"manicures\", \"margarita\", \"margarita\", \"married\", \"marshmallows\", \"massage\", \"massage\", \"massage\", \"massage\", \"massage\", \"massages\", \"massages\", \"meat\", \"meat\", \"meat\", \"meat\", \"meat\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"milk\", \"milk\", \"milk\", \"milk\", \"milk\", \"minced\", \"minutes\", \"minutes\", \"minutes\", \"minutes\", \"minutes\", \"moist\", \"moist\", \"moist\", \"moist\", \"moist\", \"momofuku\", \"mon\", \"mon\", \"mon\", \"motel\", \"motel\", \"motel\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"mule\", \"my\", \"my\", \"my\", \"my\", \"my\", \"nacho\", \"nacho\", \"nail\", \"nail\", \"nail\", \"nail\", \"nail\", \"nails\", \"nails\", \"nails\", \"nails\", \"nails\", \"nancy\", \"needed\", \"needed\", \"needed\", \"needed\", \"needed\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"night\", \"nyc\", \"nyc\", \"office\", \"office\", \"office\", \"office\", \"office\", \"ok\", \"ok\", \"ok\", \"ok\", \"ok\", \"order\", \"order\", \"order\", \"order\", \"order\", \"ordered\", \"ordered\", \"ordered\", \"ordered\", \"ordered\", \"overlooked\", \"pa\", \"painting\", \"pakora\", \"paperwork\", \"paperwork\", \"park\", \"park\", \"park\", \"park\", \"park\", \"patients\", \"patients\", \"patients\", \"patients\", \"patients\", \"pearls\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicure\", \"pee\", \"people\", \"people\", \"people\", \"people\", \"people\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"persian\", \"pet\", \"pet\", \"pet\", \"pet\", \"pet\", \"philly\", \"philly\", \"pho\", \"pho\", \"pho\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"photography\", \"photography\", \"pico\", \"pico\", \"pig\", \"pig\", \"pig\", \"pig\", \"pinch\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"place\", \"place\", \"place\", \"place\", \"place\", \"polish\", \"polish\", \"polish\", \"polish\", \"pool\", \"pool\", \"pool\", \"pool\", \"pool\", \"pork\", \"pork\", \"pork\", \"pork\", \"pork\", \"poutine\", \"poutine\", \"poutine\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"procedure\", \"procedure\", \"promotion\", \"protein\", \"protein\", \"protein\", \"protein\", \"pt\", \"quote\", \"quote\", \"quote\", \"quote\", \"quote\", \"ragu\", \"rain\", \"ramen\", \"ramen\", \"ramen\", \"ramen\", \"ramen\", \"ramsay\", \"ranchero\", \"reach\", \"reach\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"relaxing\", \"relaxing\", \"relaxing\", \"relaxing\", \"relaxing\", \"relleno\", \"repair\", \"repair\", \"repair\", \"repair\", \"repair\", \"repaired\", \"repaired\", \"repaired\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"rewards\", \"rick\", \"rita\", \"roll\", \"roll\", \"roll\", \"roll\", \"roll\", \"rolls\", \"rolls\", \"rolls\", \"rolls\", \"rolls\", \"roof\", \"roof\", \"roof\", \"roof\", \"roof\", \"room\", \"room\", \"room\", \"room\", \"room\", \"rooms\", \"rooms\", \"rooms\", \"rooms\", \"rooms\", \"rude\", \"rude\", \"rude\", \"rude\", \"rude\", \"said\", \"said\", \"said\", \"said\", \"said\", \"salad\", \"salad\", \"salad\", \"salad\", \"salad\", \"sales\", \"sales\", \"sales\", \"sales\", \"sales\", \"salon\", \"salon\", \"salon\", \"salon\", \"salon\", \"salsa\", \"salsa\", \"salsa\", \"salsa\", \"salsa\", \"samosa\", \"sampling\", \"sashimi\", \"sashimi\", \"sashimi\", \"sashimi\", \"sashimi\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"scorpions\", \"seats\", \"seats\", \"seats\", \"seats\", \"seats\", \"server\", \"server\", \"server\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"service\", \"services\", \"services\", \"services\", \"services\", \"services\", \"sessions\", \"sessions\", \"shakes\", \"shakes\", \"shakes\", \"shakes\", \"shakes\", \"she\", \"she\", \"she\", \"she\", \"she\", \"shower\", \"shower\", \"shower\", \"shower\", \"shower\", \"situation\", \"situation\", \"situation\", \"situation\", \"situation\", \"skin\", \"skin\", \"skin\", \"skin\", \"skin\", \"skinny\", \"slider\", \"slider\", \"smokey\", \"smokey\", \"sourced\", \"spa\", \"spa\", \"spa\", \"spa\", \"spa\", \"specially\", \"spell\", \"staff\", \"staff\", \"staff\", \"staff\", \"staff\", \"stay\", \"stay\", \"stay\", \"stay\", \"stay\", \"stayed\", \"stayed\", \"stayed\", \"stayed\", \"stayed\", \"steak\", \"steak\", \"steak\", \"steak\", \"steak\", \"store\", \"store\", \"store\", \"store\", \"store\", \"stunning\", \"surgery\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"taco\", \"taco\", \"taco\", \"taco\", \"taco\", \"tacos\", \"tacos\", \"tacos\", \"tacos\", \"tacos\", \"tai\", \"talent\", \"talent\", \"tamale\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tea\", \"tea\", \"tea\", \"tea\", \"tea\", \"tech\", \"tech\", \"tech\", \"tech\", \"tech\", \"technique\", \"technique\", \"terrified\", \"thai\", \"thai\", \"thai\", \"thai\", \"thai\", \"the\", \"the\", \"the\", \"the\", \"the\", \"theater\", \"theater\", \"theater\", \"theater\", \"theater\", \"theaters\", \"theaters\", \"theatre\", \"theatre\", \"theatre\", \"therapist\", \"therapist\", \"there\", \"there\", \"there\", \"there\", \"there\", \"they\", \"they\", \"they\", \"they\", \"they\", \"this\", \"this\", \"this\", \"this\", \"this\", \"tilapia\", \"tile\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tire\", \"tire\", \"tire\", \"tire\", \"tire\", \"told\", \"told\", \"told\", \"told\", \"told\", \"tortilla\", \"tortilla\", \"tortilla\", \"tortilla\", \"tour\", \"tour\", \"tour\", \"tour\", \"tour\", \"towed\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tr\\u00e8s\", \"tr\\u00e8s\", \"un\", \"un\", \"un\", \"un\", \"und\", \"unorganized\", \"unorganized\", \"upgraded\", \"upgraded\", \"urban\", \"values\", \"vegan\", \"vegan\", \"vegan\", \"vegan\", \"vegan\", \"vegas\", \"vegas\", \"vegas\", \"vegas\", \"vegas\", \"victor\", \"victoria\", \"volcano\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warranty\", \"warranty\", \"water\", \"water\", \"water\", \"water\", \"water\", \"we\", \"we\", \"we\", \"we\", \"we\", \"went\", \"went\", \"went\", \"went\", \"went\", \"wine\", \"wine\", \"wine\", \"wine\", \"wine\", \"work\", \"work\", \"work\", \"work\", \"work\", \"years\", \"years\", \"years\", \"years\", \"years\", \"yellowtail\", \"yellowtail\", \"you\", \"you\", \"you\", \"you\", \"you\", \"yuk\", \"yuk\", \"\\u00e0\", \"\\u00e0\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el591396856369193762067976602\", ldavis_el591396856369193762067976602_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el591396856369193762067976602\", ldavis_el591396856369193762067976602_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el591396856369193762067976602\", ldavis_el591396856369193762067976602_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "0     -0.107676  0.051739       1        1  28.200426\n",
              "1      0.079682  0.033326       2        1  23.890856\n",
              "2      0.080771 -0.018108       3        1  22.393588\n",
              "3     -0.069613 -0.063684       4        1  13.520077\n",
              "4      0.016836 -0.003273       5        1  11.995052, topic_info=         Term         Freq        Total Category  logprob  loglift\n",
              "164      food  4777.000000  4777.000000  Default  30.0000  30.0000\n",
              "41        the  9198.000000  9198.000000  Default  29.0000  29.0000\n",
              "116      room   875.000000   875.000000  Default  28.0000  28.0000\n",
              "50       good  4524.000000  4524.000000  Default  27.0000  27.0000\n",
              "389    cheese   833.000000   833.000000  Default  26.0000  26.0000\n",
              "...       ...          ...          ...      ...      ...      ...\n",
              "313        if   151.110068  1023.853500   Topic5  -6.0695   0.2074\n",
              "349      want   144.169226   969.265978   Topic5  -6.1165   0.2151\n",
              "146    people   152.820763  1411.975531   Topic5  -6.0582  -0.1028\n",
              "817      love   155.399845  1608.750573   Topic5  -6.0415  -0.2165\n",
              "1400  chicken   148.705629  1391.207671   Topic5  -6.0855  -0.1153\n",
              "\n",
              "[482 rows x 6 columns], token_table=       Topic      Freq   Term\n",
              "term                         \n",
              "1268       1  0.149351   \\n\\n\n",
              "1268       2  0.209091   \\n\\n\n",
              "1268       3  0.270589   \\n\\n\n",
              "1268       4  0.122995   \\n\\n\n",
              "1268       5  0.247747   \\n\\n\n",
              "...      ...       ...    ...\n",
              "1000       5  0.088543    you\n",
              "14263      1  0.974826    yuk\n",
              "14263      2  0.017102    yuk\n",
              "4339       2  0.875543      à\n",
              "4339       5  0.111771      à\n",
              "\n",
              "[1210 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f44a26c754500ff0bf585296075bf754",
          "grade": false,
          "grade_id": "cell-bf9e63d9645bba84",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "MnzDyuDyvlDb"
      },
      "source": [
        "#### 3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF1WD8QBPTmX"
      },
      "source": [
        "Here were the top unique words in each topic:\n",
        "\n",
        "topic 1: time, service, customer, car, day, experience\n",
        "\n",
        "-May be businesses like car rental or car dealer.\n",
        "\n",
        "topic 2: service, chicken, friendly, delicious, fresh\n",
        "\n",
        "-Healthy restaurant\n",
        "\n",
        "topic 3: cheese, best, try, meat, sauce, salad, fries\n",
        "\n",
        "-Not healthy restaurant\n",
        "\n",
        "topic 4: room, time, nice, people, love, hotel, clean\n",
        "\n",
        "-Hotels\n",
        "\n",
        "topic 5: time, restaurant, pizza, pretty, night\n",
        "\n",
        "-Trendy restaurant\n",
        "\n",
        "This could have used more text cleaning to take out the most common words, perhaps some lemmatization too. There's a lot of overlapping words in it now that make it difficult to identify what the topics are.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znTWB75qvlDd"
      },
      "source": [
        "## Stretch Goals\n",
        "\n",
        "Complete one of more of these to push your score towards a three: \n",
        "* Incorporate named entity recognition into your analysis\n",
        "* Compare vectorization methods in the classification section\n",
        "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
        "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
        "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
      ]
    }
  ]
}